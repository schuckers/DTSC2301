{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beyond Linearity 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to add some additional packages to make this work.\n",
    "\n",
    "So start with *pip3 install ISLP*.  ISLP is a package from a book entitled 'Introduction to Statistical Learning with Python'.\n",
    "\n",
    "We'll also need the *pygam* package.\n",
    "\n",
    "Then *pip3 install pygam*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (summarize,\n",
    "                         poly,\n",
    "                         ModelSpec as MS)\n",
    "from statsmodels.stats.anova import anova_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygam import (s as s_gam,\n",
    "                   l as l_gam,\n",
    "                   f as f_gam,\n",
    "                   LinearGAM,\n",
    "                   LogisticGAM)\n",
    "\n",
    "from ISLP.transforms import (BSpline,\n",
    "                             NaturalSpline)\n",
    "from ISLP.models import bs, ns\n",
    "from ISLP.pygam import (approx_lam,\n",
    "                        degrees_of_freedom,\n",
    "                        plot as plot_gam,\n",
    "                        anova as anova_gam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start with some data on wages.  We'll look at the data on wages with age as a predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wage = load_data('Wage')\n",
    "print(Wage.info())\n",
    "y = Wage['wage']\n",
    "age = Wage['age']\n",
    "Wage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter( Wage['age'],Wage['wage'],s=1)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Wage' )\n",
    "plt.title('Plot of Age vs Wage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that scatterplot suggests that we have a non-linear relationship here.\n",
    "\n",
    "So let's build some non-linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial regression means that we have a regression with predictors $x$, $x^2$, $x^3$, ..., to $x^d$ where\n",
    "$d$ is the degree of the polynomial.  So a cubic is of degree 3 and a linear function would be of degree 1.\n",
    "\n",
    "We will do this in a special way that make the predictors not be correlated.  Math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This builds the fourth degree polynomial predictors for age\n",
    "# so that we have in poly_age: age, age^2, age^3, age^4\n",
    "poly_age = MS([poly('age', degree=4)]).fit(Wage)\n",
    "# Use the polynomials of age to fit a regression model an \n",
    "# ordinary least squares (OLS) one \n",
    "M = sm.OLS(y, poly_age.transform(Wage)).fit()\n",
    "# get the summary for this model\n",
    "summarize(M)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output above, we have the y-intercept (111.7), then the coefficient for age (447.1), the coefficient for age^2 (-478.3),\n",
    "    the coefficient for age^3 (125.5) and the coefficient for age^4 (-77.9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For making predictions, we create a set of values in *age_grid* and then we'll match the structure of the polynomials\n",
    "by transforming them to make them not correlated as we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a set of 100 values from the smallest age to the largest age\n",
    "age_grid = np.linspace(age.min(),\n",
    "                       age.max(),\n",
    "                       100)\n",
    "print(age_grid)\n",
    "\n",
    "# put those values into a dataframe called age_df\n",
    "age_df = pd.DataFrame({'age': age_grid})\n",
    "# make the values at which we are going to predict and transform them \n",
    "Xnew = poly_age.transform(age_df)\n",
    "# generated predicted values at the values in age_grid\n",
    "preds = M.get_prediction(Xnew)\n",
    "\n",
    "#print(preds.summary_frame())\n",
    "age_df['preds']=preds.predicted_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we make a plot and add the prediction equation in red to the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter( Wage['age'],Wage['wage'],s=1)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Wage' )\n",
    "plt.title('Plot of Age vs Wage')\n",
    "\n",
    "\n",
    "# Add regression line to plot\n",
    "plt.plot(age_df['age'],age_df['preds'] , color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot is the fourth order polynomial model for prediction of an individuals wage by age.\n",
    "\n",
    "Note that the model is not quadratic as it has an extended area of peak which is not \n",
    "the form that a quadratic would take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splines\n",
    "\n",
    "Polynomials give us some flexibility in the relationship between our response/target and our \n",
    "features/predictors.  A *spline* is another way to build some flexibility into that relationship.\n",
    "\n",
    "The idea of a spliced lines, or splines, is to fit a functional curve, by default cubic, to data in a window, then\n",
    "fit another  curve to the next window, etc through all the windows, and have the lines be spliced together.\n",
    "Where the windows come together are called knots because they 'tie together' one curve to the next.\n",
    "\n",
    "We do this by creating bases, see Linear Algebra, as predictors which are effectively perpendicular to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `BSpline()`  function generates the\n",
    "entire matrix of basis functions for splines with the specified set of\n",
    "knots. By default, the B-splines produced are cubic. To change the degree, use\n",
    "the argument `degree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BSplines are basis splines (bs)\n",
    "# basically these are orthogonal, read perpendicular, predictors that ensure there \n",
    "# is not much multicollinearity between them\n",
    "# the knots are the locations on the x axis\n",
    "bs_1 = BSpline(internal_knots=[25,40,60], intercept=True).fit(age)\n",
    "# transform the splines to fit the age and the function below\n",
    "bs_age = bs_1.transform(age)\n",
    "# get the number of rows and columns for bs_age\n",
    "bs_age.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of code makes the necessary predictors to have splines between knots \n",
    "at ages 25, 40 and 60.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_age = MS([bs('age', degree=3,internal_knots=[25,40,60])])\n",
    "# MS is a function that takes python sequences and makes them into a matrix\n",
    "Xbs = bs_age.fit_transform(Wage)\n",
    "# The fit_transform() method in Python, particularly within the scikit-learn library, \n",
    "# serves as a combined operation of fitting and transforming data. \n",
    "# It is commonly used in data preprocessing steps for machine learning. \n",
    "# The fit() part calculates necessary parameters from the data, \n",
    "# such as mean and standard deviation in the case of scaling. \n",
    "# The transform() part then applies these calculated parameters to transform the data. \n",
    "# Using fit_transform() performs both actions sequentially in a single step, \n",
    "# which can be more efficient than calling fit() and transform() separately.\n",
    "\n",
    "# fit a regression model to these data with y as the response and Xbs as our predictors\n",
    "# call that model M2\n",
    "M2 = sm.OLS(y, Xbs).fit()\n",
    "# get the coefficient summary for M2\n",
    "summarize(M2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are 6 spline coefficients rather than 7. This is because, by default, `bs()` assumes `intercept=False`, since we typically have an overall intercept in the model. So it generates the spline basis with the given knots,  and then discards one of the basis functions to account for the intercept. \n",
    "\n",
    "We could also use the `df` (degrees of freedom) option to specify the complexity of the spline.  We see above that with 3 knots, the spline basis has 6 columns or degrees of freedom.  When we specify `df=6` rather than the actual knots, `bs()` will produce a spline with 3 knots chosen at uniform quantiles of the training data.  \n",
    "\n",
    "We can see these chosen knots most easily using `Bspline()` directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSpline(df=6).fit(age).internal_knots_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will make predictions so we can plot and compare how the splines do compared to the polynomial regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data for making predictions based upon the bs_age transformation\n",
    "Xnew = bs_age.transform(age_df)\n",
    "# get the predicted values from M2 which is our regression model\n",
    "preds2 = M2.get_prediction(Xnew)\n",
    "\n",
    "# M2.get_prediction gives a bunch of output we just wanted the predicted values/means\n",
    "age_df['preds2']=preds2.predicted_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next make the plots and compare the polynomial in *red* to the splines in *blue*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter( Wage['age'],Wage['wage'],s=1, color=\"grey\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Wage' )\n",
    "plt.title('Plot of Age vs Wage')\n",
    "\n",
    "\n",
    "# Add prediction line to plot\n",
    "plt.plot(age_df['age'],age_df['preds2'] , color='blue')\n",
    "# Add prediction line to plot\n",
    "plt.plot(age_df['age'],age_df['preds'],color=\"red\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions are similar but with some slight differences between the polynomial and the spline fit.\n",
    "If we were to change the polynomial order or the type of spline we would get different predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will change the type of spline to be linear (degree=1) and refit the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_age2 = MS([bs('age', degree=1,internal_knots=[25,40,60])])\n",
    "# MS is a function that takes python sequences and makes them into a matrix\n",
    "Xbs2 = bs_age2.fit_transform(Wage)\n",
    "# The fit_transform() method in Python, particularly within the scikit-learn library, \n",
    "# serves as a combined operation of fitting and transforming data. \n",
    "# It is commonly used in data preprocessing steps for machine learning. \n",
    "# The fit() part calculates necessary parameters from the data, \n",
    "# such as mean and standard deviation in the case of scaling. \n",
    "# The transform() part then applies these calculated parameters to transform the data. \n",
    "# Using fit_transform() performs both actions sequentially in a single step, \n",
    "# which can be more efficient than calling fit() and transform() separately.\n",
    "\n",
    "# fit a regression model to these data with y as the response and Xbs as our predictors\n",
    "# call that model M2\n",
    "M3 = sm.OLS(y, Xbs2).fit()\n",
    "# get the coefficient summary for M2\n",
    "summarize(M3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've not interpreted these coefficients since they are a challenge to interpret since they depend upon the basis functions that were defined.  What we can tell is that since all of the above coefficients have small p-values, that they are worth keeping in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will get the predictions for the model *M3*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew = bs_age2.transform(age_df)\n",
    "\n",
    "preds3 = M3.get_prediction(Xnew)\n",
    "\n",
    "#print(preds.summary_frame())\n",
    "age_df['preds3']=preds3.predicted_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter( Wage['age'],Wage['wage'],s=1)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Wage' )\n",
    "plt.title('Plot of Age vs Wage')\n",
    "\n",
    "\n",
    "# Add prediction line to plot\n",
    "plt.plot(age_df['age'],age_df['preds2'] , color='blue')\n",
    "# Add prediction line to plot\n",
    "plt.plot(age_df['age'],age_df['preds'],color=\"red\")\n",
    "# Add prediction line for degree =2 spline\n",
    "plt.plot(age_df['age'],age_df['preds3'],color=\"black\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the y-axis so that we can more closely see that is going on.  \n",
    "\n",
    "We'll do that below with the *plt.ylim* command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note here that the addition of s=1 makes for \n",
    "plt.scatter( Wage['age'],Wage['wage'],s=1)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Wage' )\n",
    "plt.title('Plot of Age vs Wage')\n",
    "\n",
    "\n",
    "# Add prediction line to plot\n",
    "plt.plot(age_df['age'],age_df['preds2'] , color='green')\n",
    "# Add prediction line to plot\n",
    "plt.plot(age_df['age'],age_df['preds'],color=\"red\")\n",
    "# Add prediction line for degree =2 spline\n",
    "plt.plot(age_df['age'],age_df['preds3'],color=\"black\")\n",
    "\n",
    "plt.ylim([40,140])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specified knots at Age = 25,Age = 40, and Age =60.  From the black curve, which has a linear fit \n",
    "in each window we can clearly see the 'elbows' at those age values where the predicted curve \n",
    "changes slope while still being 'smooth' (or even continuous in a mathematical sense).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks\n",
    "\n",
    "1. Read in National Football League historical draft data located at http://myslu.stlawu.edu/~msch/data/NFLDraft.csv .  *G* is the number of games played by a player in their career. *Pick* is the position at which they were selected in the National Football League (NFL) draft. Plot G vs Pick.  The NFL allocates new players to teams by having teams select among a pool of available players.  \n",
    "\n",
    "3. With G as the response and Pick as the predictor, fit a 4th degree polynomial, and a basis spline with four knots at 30, 60, 90 and 120 that is degree 3, and another basis spline with the same knots that is degree 1.\n",
    "\n",
    "4. Plot the predicted functions for your models above.\n",
    "    \n",
    "5. How might you evaluation which method does the best job of prediction?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the blue jay data\n",
    "nfl = pd.read_csv(\"http://myslu.stlawu.edu/~msch/data/NFLDraft.csv\")\n",
    "# remove rows with missing data\n",
    "#nfl.dropna(inplace=True)\n",
    "\n",
    "nfl.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code below fills in missing values with zeros for each features/columns.\n",
    "# we do this since if a player did not have a value we assume they \n",
    "# never played in a game, 'G  '\n",
    "# or never started a game 'GS'\n",
    "# or never had any career approximate value 'CarAV  '\n",
    "nfl['G  ']=nfl['G  '].fillna(0)\n",
    "nfl['GS']=nfl['GS'].fillna(0)\n",
    "nfl['CarAV  ']=nfl['CarAV  '].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot G vs. Pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(nfl['Pick  '],  nfl['G  '])\n",
    "plt.xlabel('Pick')\n",
    "plt.ylabel('Games Played ')\n",
    "plt.title('Plot of Games Played vs Pick')\n",
    "# Add labels and title\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default size for the points is large, so let's make that smaller. This plot will make the trend a bit easier to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(nfl['Pick  '],  nfl['G  '],s=5)\n",
    "plt.xlabel('Pick')\n",
    "plt.ylabel('Games Played ')\n",
    "plt.title('Plot of Games Played vs Pick')\n",
    "# Add labels and title\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use an argument called alpha to make some of the points transparent.  Alpha takes\n",
    "values between 0 and 1 and larger values of alpha are less transparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(nfl['Pick  '],  nfl['G  '], s=6,alpha=0.3)\n",
    "plt.xlabel('Pick')\n",
    "plt.ylabel('Games Played ')\n",
    "plt.title('Plot of Games Played vs Pick')\n",
    "# Add labels and title\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a fourth degree polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nfl.info())\n",
    "pick = nfl['Pick  ']\n",
    "games = nfl['G  ']\n",
    "# This builds the fourth degree polynomial predictors for age\n",
    "# so that we have in poly_age: age, age^2, age^3, age^4\n",
    "#\n",
    "# pass to MS the column name in poly() and the dataframe name in fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_pick = MS([poly('Pick  ', degree=4)]).fit(nfl)\n",
    "# Use the polynomials of age to fit a regression model an \n",
    "# ordinary least squares (OLS) one \n",
    "M = sm.OLS(games, poly_pick.transform(nfl)).fit()\n",
    "# get the summary for this model\n",
    "summarize(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a set of 100 values from the smallest age to the largest age\n",
    "pick_grid = np.linspace(pick.min(),\n",
    "                       pick.max(),\n",
    "                       200)\n",
    "print(pick_grid)\n",
    "\n",
    "# put those values into a dataframe called pick_df\n",
    "\n",
    "# for the dataframe that we make below we need to name the column\n",
    "# the same name as the predictor in the model so that when \n",
    "# we use this dataframe for prediction the model can find the right\n",
    "# variable\n",
    "pick_df = pd.DataFrame({'Pick  ': pick_grid})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make the values at which we are going to predict and transform them \n",
    "Xnew = poly_pick.transform(pick_df)\n",
    "# generated predicted values at the values in age_grid\n",
    "preds = M.get_prediction(Xnew)\n",
    "\n",
    "#print(preds.summary_frame())\n",
    "pick_df['preds_poly']=preds.predicted_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a basis spline with four knots at 30, 60, 90 and 120 that is degree 3,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_pick = MS([bs('Pick  ', degree=3,internal_knots=[30,60,90,120])])\n",
    "# MS is a function that takes python sequences and makes them into a matrix\n",
    "Xbs = bs_pick.fit_transform(nfl)\n",
    "# The fit_transform() method in Python, particularly within the scikit-learn library, \n",
    "# serves as a combined operation of fitting and transforming data. \n",
    "# It is commonly used in data preprocessing steps for machine learning. \n",
    "# The fit() part calculates necessary parameters from the data, \n",
    "# such as mean and standard deviation in the case of scaling. \n",
    "# The transform() part then applies these calculated parameters to transform the data. \n",
    "# Using fit_transform() performs both actions sequentially in a single step, \n",
    "# which can be more efficient than calling fit() and transform() separately.\n",
    "\n",
    "# fit a regression model to these data with y as the response and Xbs as our predictors\n",
    "# call that model M2\n",
    "M_nfl = sm.OLS(games, Xbs).fit()\n",
    "# get the coefficient summary for M2\n",
    "summarize(M_nfl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew = bs_pick.transform(pick_df)\n",
    "# generated predicted values at the values in age_grid\n",
    "preds_spline3 = M_nfl.get_prediction(Xnew)\n",
    "\n",
    "#print(preds.summary_frame())\n",
    "pick_df['preds_spline3']=preds_spline3.predicted_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit another basis spline with the same knots that is degree 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_pick2 = MS([bs('Pick  ', degree=1,internal_knots=[30,60,90,120])])\n",
    "# MS is a function that takes python sequences and makes them into a matrix\n",
    "Xbs2 = bs_pick2.fit_transform(nfl)\n",
    "# The fit_transform() method in Python, particularly within the scikit-learn library, \n",
    "# serves as a combined operation of fitting and transforming data. \n",
    "# It is commonly used in data preprocessing steps for machine learning. \n",
    "# The fit() part calculates necessary parameters from the data, \n",
    "# such as mean and standard deviation in the case of scaling. \n",
    "# The transform() part then applies these calculated parameters to transform the data. \n",
    "# Using fit_transform() performs both actions sequentially in a single step, \n",
    "# which can be more efficient than calling fit() and transform() separately.\n",
    "\n",
    "# fit a regression model to these data with y as the response and Xbs as our predictors\n",
    "# call that model M2\n",
    "M_nfl2 = sm.OLS(games, Xbs2).fit()\n",
    "# get the coefficient summary for M2\n",
    "summarize(M_nfl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnew = bs_pick2.transform(pick_df)\n",
    "# generated predicted values at the values in age_grid\n",
    "preds_spline1 = M_nfl2.get_prediction(Xnew)\n",
    "\n",
    "#print(preds.summary_frame())\n",
    "pick_df['preds_spline1']=preds_spline1.predicted_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Plot the predicted functions for your models above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(nfl['Pick  '],  nfl['G  '],s=5)\n",
    "plt.xlabel('Pick')\n",
    "plt.ylabel('Games Played ')\n",
    "plt.title('Plot of Games Played vs Pick')\n",
    "\n",
    "\n",
    "# Add prediction line to plot\n",
    "plt.plot(pick_df['Pick  '],pick_df['preds_poly'] , color='yellow')\n",
    "# Add prediction line to plot\n",
    "plt.plot(pick_df['Pick  '],pick_df['preds_spline3'],color=\"purple\")\n",
    "# Add prediction line for degree =2 spline\n",
    "plt.plot(pick_df['Pick  '],pick_df['preds_spline1'],color=\"blue\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These curves look pretty similar; let's change the scales of the axes on the graph to get a better look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(nfl['Pick  '],  nfl['G  '],s=5)\n",
    "plt.xlabel('Pick')\n",
    "plt.ylabel('Games Played ')\n",
    "plt.title('Plot of Games Played vs Pick')\n",
    "\n",
    "\n",
    "# Add prediction line to plot\n",
    "plt.plot(pick_df['Pick  '],pick_df['preds_poly'] , color='yellow')\n",
    "# Add prediction line to plot\n",
    "plt.plot(pick_df['Pick  '],pick_df['preds_spline3'],color=\"purple\")\n",
    "# Add prediction line for degree =2 spline\n",
    "plt.plot(pick_df['Pick  '],pick_df['preds_spline1'],color=\"blue\")\n",
    "\n",
    "# change the range of values that will be plotted on the y-axis\n",
    "plt.ylim(0,150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. How might you evaluation which method does the best job of prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best method is likely to be looking at the RMSE's for each model and evaluating their prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
