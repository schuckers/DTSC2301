{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the libraries and functions that we will need as we do this work.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    " \n",
    "import scipy.stats as st\n",
    "import statsmodels.api as sm \n",
    "import pylab as py \n",
    "\n",
    "# here are some of the tools we will use for our analyses\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import PredictionErrorDisplay\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers, Leverage, Influence\n",
    "\n",
    "In this Jupyter Notebook we will look at outliers, leverage points and influence points.  Leverage\n",
    "is a function of where a value or observation falls relative to the other data.  If it is far from other\n",
    "observations then it potentially has leverage to change our prediction equation.\n",
    "\n",
    "An influential point is one that has both a large leverage and large residual (when that point \n",
    "is removed) so that it seems to be *influencing* the prediction equation.\n",
    "\n",
    "We'll start with the blue jay data below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the blue jay data\n",
    "bluejay = pd.read_csv(\"https://webpages.charlotte.edu/mschuck1/classes/DTSC2301/Data/BlueJays.csv\", na_values=['NA'])\n",
    "# remove rows with missing data\n",
    "bluejay.dropna(inplace=True)\n",
    "bluejay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# below we build a multiple regression model with three predictors\n",
    "#  Predictors here are Head, BillDepth, and BillLength\n",
    "# Our target variable will be the Mass of the blue jay \n",
    "\n",
    "X = bluejay[['Head', 'BillDepth', 'BillLength']]  \n",
    "y = bluejay['Mass']  \n",
    "\n",
    "\n",
    "# Create a linear regression model\n",
    "blue_model = LinearRegression()\n",
    "\n",
    "# Fit the model on the  data\n",
    "blue_model.fit(X, y)\n",
    "\n",
    "# Make predictions on the  data\n",
    "y_hat = blue_model.predict(X)\n",
    "\n",
    "# Evaluate the model performance\n",
    "rmse = root_mean_squared_error(y, y_hat)\n",
    "print('Root Mean Squared Error:', rmse)\n",
    "\n",
    "# Get the coefficients and intercept\n",
    "print('Coefficients:', blue_model.coef_)\n",
    "print('Intercept:', blue_model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this particular model formulation we need to add a \n",
    "# column of 1's to the feature array\n",
    "#add constant to predictor variables\n",
    "x2 = sm.add_constant(X)\n",
    "\n",
    "#fit linear regression model using OLS\n",
    "blue_model2 = sm.OLS(y, x2).fit()\n",
    "\n",
    "#view model summary\n",
    "print(blue_model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = x2.columns\n",
    "\n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(x2.values, i)\n",
    "                          for i in range(len(x2.columns))]\n",
    "\n",
    "print(vif_data[1:len(x2.columns)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multicollinearity does not seem to be a problem here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate leverage statistics\n",
    "leverage = blue_model2.get_influence().hat_matrix_diag\n",
    "print(leverage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above are our leverage values.  We're only going to worry if any of them are more\n",
    "than $2*(k+1)/n =2*4/123 = 0.0650$ where $k$ is the number of predictors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Cook's distance\n",
    "cook_distance = blue_model2.get_influence().cooks_distance[0]\n",
    "print(np.round(cook_distance,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above are our cooks distance values.  We will be concerned if any of them are more than\n",
    "$0.5$ and we will be very concerned if any are more than $1.0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate studentized residuals\n",
    "# recall that standardized residuals are residuals divided by standard deviation of all the residuals.\n",
    "# \n",
    "# studentized residuals are residuals divided by standard deviation of the residuals if \n",
    "# the particular residual is not included.\n",
    "\n",
    "studentized_residuals = blue_model2.get_influence().resid_studentized_external\n",
    "\n",
    "print(studentized_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# here we will identify any that are of concern\n",
    "\n",
    "\n",
    "# Identify large leverage points\n",
    "leverage_points = np.where(leverage > np.mean(leverage) + 2 * np.std(leverage))\n",
    "print(leverage_points)\n",
    "\n",
    "# Identify influential observations based on Cook's distance\n",
    "influential_observations = np.where(cook_distance > 0.5)\n",
    "print(influential_observations)\n",
    "\n",
    "x=bluejay['Head']\n",
    "y=bluejay['Mass']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The leverage points are 7, 17, 69 and 81 which correspond to the row numbers for those data.\n",
    "\n",
    "There do not appear to be any influential points.  Let's look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bluejay.loc[leverage_points])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard to identify what these are leverage points without some additional information.  Let's look at the mean \n",
    "and standard deviation for the variables that are predictors/features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean of Bill Depth is \", np.round(np.mean(bluejay['BillDepth']),2))\n",
    "print(\"Standard deviation of Bill Depth is \", np.round(np.std(bluejay['BillDepth']),2))\n",
    "print(\"Mean of Head is \", np.round(np.mean(bluejay['Head']),2))\n",
    "print(\"Standard deviation of Head is \", np.round(np.std(bluejay['Head']),2))\n",
    "print(\"Mean of Bill Length is \", np.round(np.mean(bluejay['BillLength']),2))\n",
    "print(\"Standard deviation of Bill Length is \", np.round(np.std(bluejay['BillLength']),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get a sense of why the four values that were chosen were leverage points.  Below large(small) is measured\n",
    "in number of standard deviations above(below) the mean.\n",
    "\n",
    "For the first one, the head size is very large as is the bill length.\n",
    "\n",
    "For the second one, head size seems to be very large.\n",
    "\n",
    "For the third one, all of the predictors are very small.\n",
    "\n",
    "For the fourth one, bill length seems to be the variable that likely is leading to a large leverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data to dataframe called ames\n",
    "ames = pd.read_csv(\"https://webpages.charlotte.edu/mschuck1/classes/DTSC2301/Data/Ames_house_prices.csv\", na_values=['?'])\n",
    "# replace the ? in the data with NaN for missing values\n",
    "ames.replace([' ?'],np.nan)\n",
    "# show information about the dataframe\n",
    "ames.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model1=LinearRegression()\n",
    "\n",
    "X = ames[['LotArea', 'GrLivArea', 'BsmtFinSF1']]\n",
    "# going to make a transformation of the SalePrice by\n",
    "# taking the natural logarithm of it.\n",
    "y = np.log(ames['SalePrice'])\n",
    "\n",
    "# fit the linear regression to the data.\n",
    "model1.fit(X,y)\n",
    "\n",
    "# make the residual vs fitted plot\n",
    "y_hat = model1.predict(X)\n",
    "# below makes a \n",
    "display = PredictionErrorDisplay(y_true=y, y_pred=y_hat)\n",
    "display.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = sm.add_constant(X)\n",
    "\n",
    "#fit linear regression model using OLS\n",
    "model1 = sm.OLS(y, x2).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate leverage statistics\n",
    "leverage = model1.get_influence().hat_matrix_diag\n",
    "cook_distance = model1.get_influence().cooks_distance[0]\n",
    "studentized_residuals = model1.get_influence().resid_studentized_external\n",
    "\n",
    "\n",
    "\n",
    "# Identify large leverage points\n",
    "leverage_points = np.where(leverage > np.mean(leverage) + 2 * np.std(leverage))\n",
    "print(\"These are the leverage points\")\n",
    "print(leverage_points)\n",
    "\n",
    "# Identify influential observations based on Cook's distance\n",
    "influential_observations = np.where(cook_distance > 0.5)\n",
    "print(\"These are the influential points\")\n",
    "print(influential_observations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "So here we have some leverage points, eight of them. And one influential point, in row 1298."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ames.loc[influential_observations])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That SalePrice seems low but it is hard to tell from the output we got.  Let's make it bit more \n",
    "targeted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ames[['LotArea', 'GrLivArea', 'BsmtFinSF1','SalePrice']].loc[influential_observations])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the SalePrice seems low for such a large house.  Let's look at the studentized residual for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(studentized_residuals[influential_observations])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's quite a negative residual and, no doubt, the reason that there are "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit a multiple regression to the penguins data with body mass as the response and flipper length and \n",
    "bill length as features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Determine if there are any unusual residuals, any leverage points or any influential points in the regression\n",
    "that you made in the previous task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
