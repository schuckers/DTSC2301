{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dde3cef",
   "metadata": {},
   "source": [
    "## Model Validation and Cross-Validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fd4324",
   "metadata": {},
   "source": [
    "In this lab, we explore some techniques for model evaluation. Some of the commands in this lab may take a while to run on your computer.\n",
    "This file is drawn from labs that are part of the book that goes with the ISLP package.\n",
    "\n",
    "[<https://github.com/intro-stat-learning/ISLP_labs/blob/stable/Ch05-resample-lab.ipynb>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1deb5cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:13.493284Z",
     "iopub.status.busy": "2024-06-04T23:19:13.492950Z",
     "iopub.status.idle": "2024-06-04T23:19:14.143174Z",
     "shell.execute_reply": "2024-06-04T23:19:14.142882Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize,\n",
    "                         poly)\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa08b62",
   "metadata": {},
   "source": [
    "There are several new imports needed for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "268c41b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:14.144884Z",
     "iopub.status.busy": "2024-06-04T23:19:14.144773Z",
     "iopub.status.idle": "2024-06-04T23:19:14.146541Z",
     "shell.execute_reply": "2024-06-04T23:19:14.146330Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import \\\n",
    "     (cross_validate,\n",
    "      KFold,\n",
    "      ShuffleSplit)\n",
    "from sklearn.base import clone\n",
    "from ISLP.models import sklearn_sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c04f8e4",
   "metadata": {},
   "source": [
    "## The Test Set Approach\n",
    "We explore the use of the test or validation set approach in order to estimate\n",
    "the test error rates that result from fitting various linear models on\n",
    "the  `Auto`  data set.\n",
    "\n",
    "We use the function `train_test_split()` to split\n",
    "the data into training and validation sets. As there are 392 observations,\n",
    "we split into two equal sets of size 196 using the\n",
    "argument `test_size=196`. It is generally a good idea to set a random seed\n",
    "when performing operations like this that contain an\n",
    "element of randomness, so that the results obtained can be reproduced\n",
    "precisely at a later time. We set the random seed of the splitter\n",
    "with the argument `random_state=0`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22f44ae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:14.147809Z",
     "iopub.status.busy": "2024-06-04T23:19:14.147730Z",
     "iopub.status.idle": "2024-06-04T23:19:14.152606Z",
     "shell.execute_reply": "2024-06-04T23:19:14.152414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 392 entries, chevrolet chevelle malibu to chevy s-10\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           392 non-null    float64\n",
      " 1   cylinders     392 non-null    int64  \n",
      " 2   displacement  392 non-null    float64\n",
      " 3   horsepower    392 non-null    int64  \n",
      " 4   weight        392 non-null    int64  \n",
      " 5   acceleration  392 non-null    float64\n",
      " 6   year          392 non-null    int64  \n",
      " 7   origin        392 non-null    int64  \n",
      "dtypes: float64(3), int64(5)\n",
      "memory usage: 27.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Auto = load_data('Auto')\n",
    "print(Auto.info())\n",
    "Auto_train, Auto_test = train_test_split(Auto,\n",
    "                                         test_size=196,\n",
    "                                         random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318fe69f",
   "metadata": {},
   "source": [
    "Now we can fit a linear regression using only the observations corresponding to the training set `Auto_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c32e917",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:14.153847Z",
     "iopub.status.busy": "2024-06-04T23:19:14.153757Z",
     "iopub.status.idle": "2024-06-04T23:19:14.157537Z",
     "shell.execute_reply": "2024-06-04T23:19:14.157339Z"
    }
   },
   "outputs": [],
   "source": [
    "hp_mm = MS(['horsepower'])\n",
    "X_train = hp_mm.fit_transform(Auto_train)\n",
    "y_train = Auto_train['mpg']\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e883b8f",
   "metadata": {},
   "source": [
    "We now use the `predict()` method of `results` evaluated on the model matrix for this model\n",
    "created using the test data set. We also calculate the test MSE of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86ce4f85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:14.158717Z",
     "iopub.status.busy": "2024-06-04T23:19:14.158637Z",
     "iopub.status.idle": "2024-06-04T23:19:14.162177Z",
     "shell.execute_reply": "2024-06-04T23:19:14.161910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(23.61661706966988)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = hp_mm.transform(Auto_test)\n",
    "y_valid = Auto_test['mpg']\n",
    "valid_pred = results.predict(X_valid)\n",
    "np.mean((y_valid - valid_pred)**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ecdee6",
   "metadata": {},
   "source": [
    "Hence our estimate for the test MSE of  the linear regression\n",
    "fit is $23.62$.\n",
    "\n",
    "We can also estimate the test error for\n",
    "higher-degree polynomial regressions. We first provide a function `evalMSE()` that takes a model string as well\n",
    "as a training and test set and returns the MSE on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50a66a97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:14.163466Z",
     "iopub.status.busy": "2024-06-04T23:19:14.163397Z",
     "iopub.status.idle": "2024-06-04T23:19:14.165323Z",
     "shell.execute_reply": "2024-06-04T23:19:14.165076Z"
    }
   },
   "outputs": [],
   "source": [
    "# define a function call evalMSE\n",
    "def evalMSE(terms,\n",
    "            response,\n",
    "            train,\n",
    "            test):\n",
    "   # create the matrix needed, mm, based upon the terms in the model\n",
    "   mm = MS(terms)\n",
    "   # make training data\n",
    "   X_train = mm.fit_transform(train)\n",
    "   y_train = train[response]\n",
    "\n",
    "   # make test data\n",
    "   X_test = mm.transform(test)\n",
    "   y_test = test[response]\n",
    "\n",
    "   # fit the regression model \n",
    "   results = sm.OLS(y_train, X_train).fit()\n",
    "   # get the predicted values from the model fit above on the test data\n",
    "   test_pred = results.predict(X_test)\n",
    "   # return the RMSE\n",
    "   return np.mean((y_test - test_pred)**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a255779c",
   "metadata": {},
   "source": [
    "Letâ€™s use this function to estimate the test MSE\n",
    "using linear, quadratic, cubic and quartic fits. We use the `enumerate()`  function\n",
    "here, which gives both the values and indices of objects as one iterates\n",
    "over a _for loop_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d49b6999",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:14.166563Z",
     "iopub.status.busy": "2024-06-04T23:19:14.166497Z",
     "iopub.status.idle": "2024-06-04T23:19:14.177198Z",
     "shell.execute_reply": "2024-06-04T23:19:14.176975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707, 18.76303135, 18.79694163, 18.77852784])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a blank array of all zeroes of length 3\n",
    "MSE = np.zeros(4)\n",
    "# create a for loop over the values \n",
    "for idx, degree in enumerate(range(1, 5)):\n",
    "    # fit different models to \n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
    "                       'mpg',\n",
    "                       Auto_train,\n",
    "                       Auto_test)\n",
    "MSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7b8fc1",
   "metadata": {},
   "source": [
    "These error rates are $23.62, 18.76$, $18.80$, and $18.78$ respectively. If we\n",
    "choose a different training/validation split instead, then we\n",
    "can expect somewhat different errors on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dac8bd54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:14.178405Z",
     "iopub.status.busy": "2024-06-04T23:19:14.178321Z",
     "iopub.status.idle": "2024-06-04T23:19:14.188650Z",
     "shell.execute_reply": "2024-06-04T23:19:14.188432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.75540796, 16.94510676, 16.97437833, 16.89589193])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Auto_train, Auto_test = train_test_split(Auto,\n",
    "                                          test_size=196,\n",
    "                                          random_state=3)\n",
    "MSE = np.zeros(4)\n",
    "for idx, degree in enumerate(range(1, 5)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
    "                       'mpg',\n",
    "                       Auto_train,\n",
    "                       Auto_test)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f2c12d",
   "metadata": {},
   "source": [
    "Using this split of the observations into a training set and a validation set,\n",
    "we find that the validation set error rates for the models with linear, quadratic, and cubic terms are $20.76$, $16.95$,$16.97$, and $16.90$ respectively.\n",
    "\n",
    "Seems like there is not much advantage to using the cubic or quartic models over the\n",
    "quadratic model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22daa51",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "In theory, the cross-validation estimate can be computed for any generalized\n",
    "linear model.  {}\n",
    "In practice, however, the simplest way to cross-validate in\n",
    "Python is to use `sklearn`, which has a different interface or API\n",
    "than `statsmodels`, the code we have been using to fit models.\n",
    "\n",
    "This is a problem which often confronts data scientists: \"I have a function to do task $A$, and need to feed it into something that performs task $B$, so that I can compute $B(A(D))$, where $D$ is my data.\" When $A$ and $B$ donâ€™t naturally speak to each other, this\n",
    "requires the use of a *wrapper*.\n",
    "In the `ISLP` package,\n",
    "we provide \n",
    "a wrapper, `sklearn_sm()`, that enables us to easily use the cross-validation tools of `sklearn` with\n",
    "models fit by `statsmodels`.\n",
    "\n",
    "The class `sklearn_sm()` \n",
    "has  as its first argument\n",
    "a model from `statsmodels`. It can take two additional\n",
    "optional arguments: `model_str` which can be\n",
    "used to specify a formula, and `model_args` which should\n",
    "be a dictionary of additional arguments used when fitting\n",
    "the model. For example, to fit a logistic regression model\n",
    "we have to specify a `family` argument. This\n",
    "is passed as `model_args={'family':sm.families.Binomial()}`.\n",
    "\n",
    "Here is our wrapper in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "601ae443",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:14.189993Z",
     "iopub.status.busy": "2024-06-04T23:19:14.189906Z",
     "iopub.status.idle": "2024-06-04T23:19:14.876368Z",
     "shell.execute_reply": "2024-06-04T23:19:14.876129Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(24.231513517929212)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_model = sklearn_sm(sm.OLS,\n",
    "                      MS(['horsepower']))\n",
    "X, Y = Auto.drop(columns=['mpg']), Auto['mpg']\n",
    "cv_results = cross_validate(hp_model,\n",
    "                            X,\n",
    "                            Y,\n",
    "                            cv=Auto.shape[0])\n",
    "cv_err = np.mean(cv_results['test_score'])\n",
    "cv_err\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebadc35f",
   "metadata": {},
   "source": [
    "The arguments to `cross_validate()` are as follows: an\n",
    "object with the appropriate `fit()`, `predict()`,\n",
    "and `score()` methods,  an\n",
    "array of features `X` and a response `Y`. \n",
    "We also included an additional argument `cv` to `cross_validate()`; specifying an integer\n",
    "$K$ results in $K$-fold cross-validation. We have provided a value \n",
    "corresponding to the total number of observations, which results in\n",
    "leave-one-out cross-validation (LOOCV). The `cross_validate()`  function produces a dictionary with several components;\n",
    "we simply want the cross-validated test score here (MSE), which is estimated to be 24.23."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f47b99",
   "metadata": {},
   "source": [
    "We can repeat this procedure for increasingly complex polynomial fits.\n",
    "To automate the process, we again\n",
    "use a for loop which iteratively fits polynomial\n",
    "regressions of degree 1 to 5, computes the\n",
    "associated cross-validation error, and stores it in the $i^{th}$ element\n",
    "of the vector `cv_error`. The variable `d` in the _for loop_\n",
    "corresponds to the degree of the polynomial. We begin by initializing the\n",
    "vector. This command may take a couple of seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11226c85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:14.877800Z",
     "iopub.status.busy": "2024-06-04T23:19:14.877726Z",
     "iopub.status.idle": "2024-06-04T23:19:15.384419Z",
     "shell.execute_reply": "2024-06-04T23:19:15.384193Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.23151352, 19.24821312, 19.33498406, 19.42443031, 19.03320428])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "H = np.array(Auto['horsepower'])\n",
    "M = sklearn_sm(sm.OLS)\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=Auto.shape[0])\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a920ae",
   "metadata": {},
   "source": [
    "We see a sharp drop in the estimated test MSE between the linear and\n",
    "quadratic fits, but then no clear improvement from using higher-degree polynomials.\n",
    "\n",
    "Above we introduced the `outer()`  method of the `np.power()`\n",
    "function.  The `outer()` method is applied to an operation\n",
    "that has two arguments, such as `add()`, `min()`, or\n",
    "`power()`.\n",
    "It has two arrays as arguments, and then forms a larger\n",
    "array where the operation is applied to each pair of elements of the\n",
    "two arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64b64d97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:15.385768Z",
     "iopub.status.busy": "2024-06-04T23:19:15.385690Z",
     "iopub.status.idle": "2024-06-04T23:19:15.387686Z",
     "shell.execute_reply": "2024-06-04T23:19:15.387484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  7],\n",
       "       [ 7,  9],\n",
       "       [11, 13]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([3, 5, 9])\n",
    "B = np.array([2, 4])\n",
    "np.add.outer(A, B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71385c1b",
   "metadata": {},
   "source": [
    "In the CV example above, we used $K=n$, but of course we can also use $K<n$. The code is very similar\n",
    "to the above (and is significantly faster). Here we use `KFold()` to partition the data into $K=10$ random groups. We use `random_state` to set a random seed and initialize a vector `cv_error` in which we will store the CV errors corresponding to the\n",
    "polynomial fits of degrees one to five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca0f972f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:15.389014Z",
     "iopub.status.busy": "2024-06-04T23:19:15.388934Z",
     "iopub.status.idle": "2024-06-04T23:19:15.407438Z",
     "shell.execute_reply": "2024-06-04T23:19:15.407194Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [392, 333]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m6\u001b[39m)):\n\u001b[0;32m      6\u001b[0m     X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpower\u001b[38;5;241m.\u001b[39mouter(H, np\u001b[38;5;241m.\u001b[39marange(d\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m----> 7\u001b[0m     M_CV \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     cv_error[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(M_CV[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     12\u001b[0m cv_error\n",
      "File \u001b[1;32mc:\\Users\\mschuck1\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mschuck1\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:345\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate metric(s) by cross-validation and also record fit/score times.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \n\u001b[0;32m    144\u001b[0m \u001b[38;5;124;03mRead more in the :ref:`User Guide <multimetric_cross_validation>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m[0.28009951 0.3908844  0.22784907]\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    343\u001b[0m _check_groups_routing_disabled(groups)\n\u001b[1;32m--> 345\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m params \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m params\n\u001b[0;32m    347\u001b[0m cv \u001b[38;5;241m=\u001b[39m check_cv(cv, y, classifier\u001b[38;5;241m=\u001b[39mis_classifier(estimator))\n",
      "File \u001b[1;32mc:\\Users\\mschuck1\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:532\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \n\u001b[0;32m    504\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    531\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 532\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\mschuck1\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:475\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    473\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    478\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [392, 333]"
     ]
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "cv = KFold(n_splits=10,\n",
    "           shuffle=True,\n",
    "           random_state=0) # use same splits for each degree\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=cv)\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b234093",
   "metadata": {},
   "source": [
    "Notice that the computation time is much shorter than that of LOOCV.\n",
    "(In principle, the computation time for LOOCV for a least squares\n",
    "linear model should be faster than for $K$-fold CV)  \n",
    "We still see little evidence that using cubic\n",
    "or higher-degree polynomial terms leads to a lower test error than simply\n",
    "using a quadratic fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4487a4",
   "metadata": {},
   "source": [
    "The `cross_validate()` function is flexible and can take\n",
    "different splitting mechanisms as an argument. For instance, one can use the `ShuffleSplit()` funtion to implement\n",
    "the test/validation set approach just as easily as K-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "080cdb29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:15.408750Z",
     "iopub.status.busy": "2024-06-04T23:19:15.408677Z",
     "iopub.status.idle": "2024-06-04T23:19:15.413979Z",
     "shell.execute_reply": "2024-06-04T23:19:15.413762Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = ShuffleSplit(n_splits=1,\n",
    "                          test_size=196,\n",
    "                          random_state=0)\n",
    "results = cross_validate(hp_model,\n",
    "                         Auto.drop(['mpg'], axis=1),\n",
    "                         Auto['mpg'],\n",
    "                         cv=validation);\n",
    "results['test_score']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f4b4cf",
   "metadata": {},
   "source": [
    "One can estimate the variability in the test error by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c46de2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:15.415225Z",
     "iopub.status.busy": "2024-06-04T23:19:15.415158Z",
     "iopub.status.idle": "2024-06-04T23:19:15.437526Z",
     "shell.execute_reply": "2024-06-04T23:19:15.437302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(23.802232661034164), np.float64(1.4218450941091847))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = ShuffleSplit(n_splits=10,\n",
    "                          test_size=196,\n",
    "                          random_state=0)\n",
    "results = cross_validate(hp_model,\n",
    "                         Auto.drop(['mpg'], axis=1),\n",
    "                         Auto['mpg'],\n",
    "                         cv=validation)\n",
    "results['test_score'].mean(), results['test_score'].std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d505e1a",
   "metadata": {},
   "source": [
    "Note that this standard deviation is not a valid estimate of the sampling variability of the mean test score or the individual scores, since the randomly-selected training samples overlap and hence introduce correlations. But it does give an idea of the Monte Carlo variation incurred by picking different random folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf5fb4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.20766449, 19.18533142, 19.27626666, 19.47848404, 19.13722016])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_error = np.zeros(5)\n",
    "cv = KFold(n_splits=10,\n",
    "           shuffle=True,\n",
    "           random_state=0) # use same splits for each degree\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=cv)\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30b7b688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.81114253, 22.2694531 , 23.94237084, 27.92859286, 22.62260018,\n",
       "       30.0976095 , 23.87376114, 27.77074161, 14.73007962, 27.03029353])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = KFold(n_splits=10,\n",
    "           shuffle=True,\n",
    "           random_state=0) # use same splits for each degree\n",
    "results = cross_validate(hp_model,\n",
    "                         Auto.drop(['mpg'], axis=1),\n",
    "                         Auto['mpg'],\n",
    "                         cv=cv);\n",
    "results['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93d539fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.61661707, 22.96552529, 23.43853845, 21.72781699, 22.79416823,\n",
       "       23.09191932, 23.69196999, 23.90184611, 26.53545818, 26.258467  ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = ShuffleSplit(n_splits=10,\n",
    "                          test_size=196,\n",
    "                          random_state=0)\n",
    "results = cross_validate(hp_model,\n",
    "                         Auto.drop(['mpg'], axis=1),\n",
    "                         Auto['mpg'],\n",
    "                         cv=cv)\n",
    "results['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb532a93",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2aef9ae9",
   "metadata": {},
   "source": [
    "Now we will to some cross validation on regression with the penguins data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0acc58e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 333 entries, 0 to 343\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            333 non-null    object \n",
      " 1   island             333 non-null    object \n",
      " 2   bill_length_mm     333 non-null    float64\n",
      " 3   bill_depth_mm      333 non-null    float64\n",
      " 4   flipper_length_mm  333 non-null    float64\n",
      " 5   body_mass_g        333 non-null    float64\n",
      " 6   sex                333 non-null    object \n",
      " 7   year               333 non-null    int64  \n",
      "dtypes: float64(4), int64(1), object(3)\n",
      "memory usage: 23.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "penguins = pd.read_csv(\"https://webpages.charlotte.edu/mschuck1/classes/DTSC2301/Data/penguins.csv\", na_values=['NA'])\n",
    "# remove rows with missing data\n",
    "penguins.dropna(inplace=True)\n",
    "penguins.head()\n",
    "print(penguins.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5df7eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pens_model = sklearn_sm(sm.OLS)\n",
    "X = penguins.drop(['species','island',\n",
    "                   'body_mass_g','sex','year'],axis=1)\n",
    "\n",
    "Y = penguins['body_mass_g'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0689460a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([468.03038214, 411.11002098, 426.66842704, 485.36520748,\n",
       "       472.61855398, 514.73290301])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cv = KFold(n_splits=6,\n",
    "           shuffle=True,\n",
    "           random_state=42)\n",
    "results = cross_validate(pens_model,\n",
    "                         X,\n",
    "                         Y,\n",
    "                         cv=cv,\n",
    "                         scoring=('neg_mean_squared_error'));\n",
    "np.sqrt(-1*results['test_score'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e7dad2",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "1. Repeat the cross validation above but remove bill depth as a predictor.\n",
    "\n",
    "2. Change the number of folds, *n_splits*, in task 1 from 6 to 10.  How does that change your RMSE results?\n",
    "\n",
    "3. Change the random seed, *random_state*, in task 1 and 2 from 42 to 20250217.  How does that change your RMSE results?\n",
    "\n",
    "4. Why might we want to change the number of splits in our code?  What are the advantages of a large number of folds and what are the advantages of a small number of folds?"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
