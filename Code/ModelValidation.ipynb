{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dde3cef",
   "metadata": {},
   "source": [
    "## Model Validation and Cross-Validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fd4324",
   "metadata": {},
   "source": [
    "In this lab, we explore some techniques for model evaluation. Some of the commands in this lab may take a while to run on your computer.\n",
    "This file is drawn from labs that are part of the book that goes with the ISLP package.\n",
    "\n",
    "[<https://github.com/intro-stat-learning/ISLP_labs/blob/stable/Ch05-resample-lab.ipynb>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1deb5cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:13.493284Z",
     "iopub.status.busy": "2024-06-04T23:19:13.492950Z",
     "iopub.status.idle": "2024-06-04T23:19:14.143174Z",
     "shell.execute_reply": "2024-06-04T23:19:14.142882Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize,\n",
    "                         poly)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa08b62",
   "metadata": {},
   "source": [
    "There are several new imports needed for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268c41b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:14.144884Z",
     "iopub.status.busy": "2024-06-04T23:19:14.144773Z",
     "iopub.status.idle": "2024-06-04T23:19:14.146541Z",
     "shell.execute_reply": "2024-06-04T23:19:14.146330Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import \\\n",
    "     (cross_validate,\n",
    "      KFold,\n",
    "      ShuffleSplit)\n",
    "from sklearn.base import clone\n",
    "from ISLP.models import sklearn_sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c04f8e4",
   "metadata": {},
   "source": [
    "## The Test Set Approach\n",
    "We explore the use of the test or validation set approach in order to estimate the test error rates that result from fitting various linear models on the  `Auto`  data set.\n",
    "\n",
    "We use the function `train_test_split()` to split the data into training and validation sets. As there are 392 observations, we split into two equal sets of size 196 using the argument `test_size=196`. It is generally a good idea to set a random seed when performing operations like this that contain an element of randomness, so that the results obtained can be reproduced precisely at a later time. We set the random seed of the splitter with the argument `random_state=0`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f44ae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:14.147809Z",
     "iopub.status.busy": "2024-06-04T23:19:14.147730Z",
     "iopub.status.idle": "2024-06-04T23:19:14.152606Z",
     "shell.execute_reply": "2024-06-04T23:19:14.152414Z"
    }
   },
   "outputs": [],
   "source": [
    "Auto = load_data('Auto')\n",
    "print(Auto.info())\n",
    "Auto_train, Auto_test = train_test_split(Auto,\n",
    "                                         test_size=196,\n",
    "                                         random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318fe69f",
   "metadata": {},
   "source": [
    "Now we can fit a linear regression using only the observations corresponding to the training set `Auto_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c32e917",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:14.153847Z",
     "iopub.status.busy": "2024-06-04T23:19:14.153757Z",
     "iopub.status.idle": "2024-06-04T23:19:14.157537Z",
     "shell.execute_reply": "2024-06-04T23:19:14.157339Z"
    }
   },
   "outputs": [],
   "source": [
    "hp_mm = MS(['horsepower'])\n",
    "X_train = hp_mm.fit_transform(Auto_train)\n",
    "y_train = Auto_train['mpg']\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e883b8f",
   "metadata": {},
   "source": [
    "We now use the `predict()` method of `results` evaluated on the model matrix for this model created using the test data set. We also calculate the test MSE of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ce4f85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:14.158717Z",
     "iopub.status.busy": "2024-06-04T23:19:14.158637Z",
     "iopub.status.idle": "2024-06-04T23:19:14.162177Z",
     "shell.execute_reply": "2024-06-04T23:19:14.161910Z"
    }
   },
   "outputs": [],
   "source": [
    "X_valid = hp_mm.transform(Auto_test)\n",
    "y_valid = Auto_test['mpg']\n",
    "valid_pred = results.predict(X_valid)\n",
    "np.mean((y_valid - valid_pred)**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ecdee6",
   "metadata": {},
   "source": [
    "Hence our estimate for the test MSE of  the linear regression fit is $23.62$.\n",
    "\n",
    "We can also estimate the test error for higher-degree polynomial regressions. We first provide a function `evalMSE()` that takes a model string as well as a training and test set and returns the MSE on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a66a97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:14.163466Z",
     "iopub.status.busy": "2024-06-04T23:19:14.163397Z",
     "iopub.status.idle": "2024-06-04T23:19:14.165323Z",
     "shell.execute_reply": "2024-06-04T23:19:14.165076Z"
    }
   },
   "outputs": [],
   "source": [
    "# define a function call evalMSE\n",
    "def evalMSE(terms,\n",
    "            response,\n",
    "            train,\n",
    "            test):\n",
    "   # create the matrix needed, mm, based upon the terms in the model\n",
    "   mm = MS(terms)\n",
    "   # make training data\n",
    "   X_train = mm.fit_transform(train)\n",
    "   y_train = train[response]\n",
    "\n",
    "   # make test data\n",
    "   X_test = mm.transform(test)\n",
    "   y_test = test[response]\n",
    "\n",
    "   # fit the regression model \n",
    "   results = sm.OLS(y_train, X_train).fit()\n",
    "   # get the predicted values from the model fit above on the test data\n",
    "   test_pred = results.predict(X_test)\n",
    "   # return the RMSE\n",
    "   return np.mean((y_test - test_pred)**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a255779c",
   "metadata": {},
   "source": [
    "Let’s use this function to estimate the test MSE using linear, quadratic, cubic and quartic fits. We use the `enumerate()`  function here, which gives both the values and indices of objects as one iterates over a _for loop_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b6999",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:14.166563Z",
     "iopub.status.busy": "2024-06-04T23:19:14.166497Z",
     "iopub.status.idle": "2024-06-04T23:19:14.177198Z",
     "shell.execute_reply": "2024-06-04T23:19:14.176975Z"
    }
   },
   "outputs": [],
   "source": [
    "# make a blank array of all zeroes of length 3\n",
    "MSE = np.zeros(4)\n",
    "# create a for loop over the values \n",
    "for idx, degree in enumerate(range(1, 5)):\n",
    "    # fit different models to \n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
    "                       'mpg',\n",
    "                       Auto_train,\n",
    "                       Auto_test)\n",
    "MSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7b8fc1",
   "metadata": {},
   "source": [
    "These error rates are $23.62, 18.76$, $18.80$, and $18.78$ respectively. If we choose a different training/validation split instead, then we can expect somewhat different errors on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac8bd54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:14.178405Z",
     "iopub.status.busy": "2024-06-04T23:19:14.178321Z",
     "iopub.status.idle": "2024-06-04T23:19:14.188650Z",
     "shell.execute_reply": "2024-06-04T23:19:14.188432Z"
    }
   },
   "outputs": [],
   "source": [
    "Auto_train, Auto_test = train_test_split(Auto,\n",
    "                                          test_size=196,\n",
    "                                          random_state=3)\n",
    "MSE = np.zeros(4)\n",
    "for idx, degree in enumerate(range(1, 5)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
    "                       'mpg',\n",
    "                       Auto_train,\n",
    "                       Auto_test)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f2c12d",
   "metadata": {},
   "source": [
    "Using this split of the observations into a training set and a validation set, we find that the validation set error rates for the models with linear, quadratic, and cubic terms are $20.76$, $16.95$,$16.97$, and $16.90$ respectively.\n",
    "\n",
    "Seems like there is not much advantage to using the cubic or quartic models over the quadratic model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22daa51",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "In theory, the cross-validation estimate can be computed for any generalized linear model.  \n",
    "\n",
    "In practice, however, the simplest way to cross-validate in Python is to use `sklearn`, which has a different interface or API than `statsmodels`, the code we have been using to fit models.\n",
    "\n",
    "This is a problem which often confronts data scientists: \"I have a function to do task $A$, and need to feed it into something that performs task $B$, so that I can compute $B(A(D))$, where $D$ is my data.\" When $A$ and $B$ don’t naturally speak to each other, this requires the use of a *wrapper*.\n",
    "\n",
    "In the `ISLP` package,we provide a wrapper, `sklearn_sm()`, that enables us to easily use the cross-validation tools of `sklearn` with models fit by `statsmodels`.\n",
    "\n",
    "The class `sklearn_sm()` has  as its first argument a model from `statsmodels`. It can take two additional optional arguments: `model_str` which can be used to specify a formula, and `model_args` which should\n",
    "be a dictionary of additional arguments used when fitting the model. For example, to fit a logistic regression model\n",
    "we have to specify a `family` argument. This is passed as `model_args={'family':sm.families.Binomial()}`.\n",
    "\n",
    "Here is our wrapper in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601ae443",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:14.189993Z",
     "iopub.status.busy": "2024-06-04T23:19:14.189906Z",
     "iopub.status.idle": "2024-06-04T23:19:14.876368Z",
     "shell.execute_reply": "2024-06-04T23:19:14.876129Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "hp_model = sklearn_sm(sm.OLS,\n",
    "                      MS(['horsepower']))\n",
    "X, Y = Auto.drop(columns=['mpg']), Auto['mpg']\n",
    "cv_results = cross_validate(hp_model,\n",
    "                            X,\n",
    "                            Y,\n",
    "                            cv=Auto.shape[0])\n",
    "cv_err = np.mean(cv_results['test_score'])\n",
    "cv_err\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebadc35f",
   "metadata": {},
   "source": [
    "The arguments to `cross_validate()` are as follows: an object with the appropriate `fit()`, `predict()`, and `score()` methods,  an\n",
    "array of features `X` and a response `Y`. \n",
    "\n",
    "We also included an additional argument `cv` to `cross_validate()`; specifying an integer $K$ results in $K$-fold cross-validation. We have provided a value \n",
    "corresponding to the total number of observations, which results in leave-one-out cross-validation (LOOCV). The `cross_validate()`  function produces a dictionary with several components;\n",
    "we simply want the cross-validated test score here (MSE), which is estimated to be 24.23."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f47b99",
   "metadata": {},
   "source": [
    "We can repeat this procedure for increasingly complex polynomial fits.  To automate the process, we again use a for loop which iteratively fits polynomial regressions of degree 1 to 5, computes the associated cross-validation error, and stores it in the $i^{th}$ element of the vector `cv_error`. The variable `d` in the _for loop_ corresponds to the degree of the polynomial. We begin by initializing the vector. This command may take a couple of seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11226c85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:14.877800Z",
     "iopub.status.busy": "2024-06-04T23:19:14.877726Z",
     "iopub.status.idle": "2024-06-04T23:19:15.384419Z",
     "shell.execute_reply": "2024-06-04T23:19:15.384193Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "cv_error = np.zeros(5)\n",
    "H = np.array(Auto['horsepower'])\n",
    "M = sklearn_sm(sm.OLS)\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=Auto.shape[0])\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a920ae",
   "metadata": {},
   "source": [
    "We see a sharp drop in the estimated test MSE between the linear and quadratic fits, but then no clear improvement from using higher-degree polynomials.\n",
    "\n",
    "Above we introduced the `outer()`  method of the `np.power()` function.  The `outer()` method is applied to an operation that has two arguments, such as `add()`, `min()`, or `power()`.\n",
    "It has two arrays as arguments, and then forms a larger array where the operation is applied to each pair of elements of the two arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b64d97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:15.385768Z",
     "iopub.status.busy": "2024-06-04T23:19:15.385690Z",
     "iopub.status.idle": "2024-06-04T23:19:15.387686Z",
     "shell.execute_reply": "2024-06-04T23:19:15.387484Z"
    }
   },
   "outputs": [],
   "source": [
    "A = np.array([3, 5, 9])\n",
    "B = np.array([2, 4])\n",
    "np.add.outer(A, B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71385c1b",
   "metadata": {},
   "source": [
    "In the CV example above, we used $K=n$, but of course we can also use $K<n$. The code is very similar to the above (and is significantly faster). Here we use `KFold()` to partition the data into $K=10$ random groups. We use `random_state` to set a random seed and initialize a vector `cv_error` in which we will store the CV errors corresponding to the polynomial fits of degrees one to five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f972f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:15.389014Z",
     "iopub.status.busy": "2024-06-04T23:19:15.388934Z",
     "iopub.status.idle": "2024-06-04T23:19:15.407438Z",
     "shell.execute_reply": "2024-06-04T23:19:15.407194Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "cv_error = np.zeros(5)\n",
    "cv = KFold(n_splits=10,\n",
    "           shuffle=True,\n",
    "           random_state=0) # use same splits for each degree\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=cv)\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b234093",
   "metadata": {},
   "source": [
    "Notice that the computation time is much shorter than that of LOOCV.\n",
    "\n",
    "(In principle, the computation time for LOOCV for a least squares linear model should be faster than for $K$-fold CV)  \n",
    "We still see little evidence that using cubic or higher-degree polynomial terms leads to a lower test error than simply using a quadratic fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4487a4",
   "metadata": {},
   "source": [
    "The `cross_validate()` function is flexible and can take different splitting mechanisms as an argument. For instance, one can use the `ShuffleSplit()` funtion to implement the test/validation set approach just as easily as K-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080cdb29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:15.408750Z",
     "iopub.status.busy": "2024-06-04T23:19:15.408677Z",
     "iopub.status.idle": "2024-06-04T23:19:15.413979Z",
     "shell.execute_reply": "2024-06-04T23:19:15.413762Z"
    },
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "validation = ShuffleSplit(n_splits=1,\n",
    "                          test_size=196,\n",
    "                          random_state=0)\n",
    "results = cross_validate(hp_model,\n",
    "                         Auto.drop(['mpg'], axis=1),\n",
    "                         Auto['mpg'],\n",
    "                         cv=validation);\n",
    "results['test_score']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f4b4cf",
   "metadata": {},
   "source": [
    "One can estimate the variability in the test error by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c46de2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T23:19:15.415225Z",
     "iopub.status.busy": "2024-06-04T23:19:15.415158Z",
     "iopub.status.idle": "2024-06-04T23:19:15.437526Z",
     "shell.execute_reply": "2024-06-04T23:19:15.437302Z"
    }
   },
   "outputs": [],
   "source": [
    "validation = ShuffleSplit(n_splits=10,\n",
    "                          test_size=196,\n",
    "                          random_state=0)\n",
    "results = cross_validate(hp_model,\n",
    "                         Auto.drop(['mpg'], axis=1),\n",
    "                         Auto['mpg'],\n",
    "                         cv=validation)\n",
    "results['test_score'].mean(), results['test_score'].std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d505e1a",
   "metadata": {},
   "source": [
    "Note that this standard deviation is not a valid estimate of the sampling variability of the mean test score or the individual scores, since the randomly-selected training samples overlap and hence introduce correlations. But it does give an idea of the Monte Carlo variation incurred by picking different random folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5fb4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_error = np.zeros(5)\n",
    "cv = KFold(n_splits=10,\n",
    "           shuffle=True,\n",
    "           random_state=0) # use same splits for each degree\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=cv)\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b7b688",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=10,\n",
    "           shuffle=True,\n",
    "           random_state=0) # use same splits for each degree\n",
    "results = cross_validate(hp_model,\n",
    "                         Auto.drop(['mpg'], axis=1),\n",
    "                         Auto['mpg'],\n",
    "                         cv=cv);\n",
    "results['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d539fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(n_splits=10,\n",
    "                          test_size=196,\n",
    "                          random_state=0)\n",
    "results = cross_validate(hp_model,\n",
    "                         Auto.drop(['mpg'], axis=1),\n",
    "                         Auto['mpg'],\n",
    "                         cv=cv)\n",
    "results['test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aef9ae9",
   "metadata": {},
   "source": [
    "Now we will do some cross validation on regression with the penguins data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acc58e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv(\"https://webpages.charlotte.edu/mschuck1/classes/DTSC2301/Data/penguins.csv\", na_values=['NA'])\n",
    "# remove rows with missing data\n",
    "penguins.dropna(inplace=True)\n",
    "penguins.head()\n",
    "print(penguins.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df7eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pens_model = sklearn_sm(sm.OLS)\n",
    "X = penguins.drop(['species','island',\n",
    "                   'body_mass_g','sex','year'],axis=1)\n",
    "\n",
    "Y = penguins['body_mass_g'] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd10dfd",
   "metadata": {},
   "source": [
    "For comparison we will build a linear regression with all of the data and compare the performance from using all of the data to what we would get on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d20e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = penguins[['bill_depth_mm', 'flipper_length_mm', 'bill_length_mm']]  \n",
    "y = penguins['body_mass_g']  \n",
    "\n",
    "\n",
    "# Create a linear regression model\n",
    "bluejay_model3 = LinearRegression()\n",
    "\n",
    "# Fit the model on the  data\n",
    "bluejay_model3.fit(X, y)\n",
    "\n",
    "# Make predictions on the  data\n",
    "y_hat = bluejay_model3.predict(X)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = root_mean_squared_error(y, y_hat)\n",
    "print('Root Mean Squared Error:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0689460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validate does not give RMSE as a possible output\n",
    "# but gives negative MSE, so we adjust that output\n",
    "cv = KFold(n_splits=6,\n",
    "           shuffle=True,\n",
    "           random_state=42)\n",
    "results = cross_validate(pens_model,\n",
    "                         X,\n",
    "                         Y,\n",
    "                         cv=cv,\n",
    "                         scoring=('neg_mean_squared_error'));\n",
    "np.sqrt(-1*results['test_score'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5bccc6",
   "metadata": {},
   "source": [
    "The RMSE for the full data regression is $390.6$ while the average for the KFold is about $450$.  So we see a drop in performance but the idea is that the latter is more likely what we would observe in application of the model to new data.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e7dad2",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "1. Fit a multiple linear regression to *all* of the data that has flipper length and bill length as predictors.  Find the RMSE.  \n",
    "\n",
    "2. Now do a K-fold cross validation of the model in Task 1 with 6 folds and find the RMSE.  How do your answers in this task compare to the answers in Task 1?  \n",
    "\n",
    "2. Change the number of folds, *n_splits*, in task 1 from 6 to 10.  How does that change your RMSE results?\n",
    "\n",
    "3. Change the random seed, *random_state*, in task 1 and 2 from 42 to 20250217.  How does that change your RMSE results?\n",
    "\n",
    "4. Why might we want to change the number of splits in our code?  What are the advantages of a large number of folds and what are the advantages of a small number of folds?"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
