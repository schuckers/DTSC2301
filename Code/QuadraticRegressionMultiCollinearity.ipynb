{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Regression and multicollinearity\n",
    "\n",
    "This Jupyter notebook is about two topics in multiple regression.  The first is quadratic regresion and the second is a concept called multicollinearity and results when the features/predictors are correlated.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Regression\n",
    "\n",
    "When we have a non-linear relationship among our data, then using a quadratic model for prediction can be useful.  \n",
    "\n",
    "The model for a quadratic regression is:\n",
    "\n",
    "$$Y= \\beta_0 + \\beta_1 X_1 + \\beta_2 X_1^2 + \\epsilon.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the libraries and functions that we will need as we do this work.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    " \n",
    "import scipy.stats as st\n",
    "import statsmodels.api as sm \n",
    "import pylab as py \n",
    "\n",
    "# here are some of the tools we will use for our analyses\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import PredictionErrorDisplay\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start with the penguins data and a relationship that we looked at previously, the relationship between flipper length (*flipper_length_mm*) and body mass (*body_mass_g*).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins = pd.read_csv(\"https://webpages.charlotte.edu/mschuck1/classes/DTSC2301/Data/penguins.csv\", na_values=['NA'])\n",
    "# remove rows with missing data\n",
    "penguins.dropna(inplace=True)\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter( penguins['flipper_length_mm'],penguins['body_mass_g'], color=\"blue\")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('flipper length in mm')\n",
    "plt.ylabel('body mass in g ')\n",
    "plt.title('Plot of flipper length vs body mass')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "When we looked at this plot before, we decided it was roughly linear, positive and moderate to strong.  \n",
    "Let's fit a linear model to these data and look at the residual plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = penguins[['flipper_length_mm']]  \n",
    "y = penguins['body_mass_g']  \n",
    "\n",
    "\n",
    "# Create a linear regression model\n",
    "p_model = LinearRegression()\n",
    "\n",
    "# Fit the model on the  data\n",
    "p_model.fit(X, y)\n",
    "\n",
    "# Make predictions on the  data\n",
    "y_hat = p_model.predict(X)\n",
    "\n",
    "# Evaluate the model performance\n",
    "rmse = root_mean_squared_error(y, y_hat)\n",
    "print('Root Mean Squared Error:', rmse)\n",
    "\n",
    "# Get the coefficients and intercept\n",
    "print('Coefficients:', p_model.coef_)\n",
    "print('Intercept:', p_model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = sm.add_constant(X)\n",
    "\n",
    "#fit linear regression model\n",
    "model2 = sm.OLS(y, x2).fit()\n",
    "\n",
    "#view model summary\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# below makes a residual vs predicted values plot\n",
    "display = PredictionErrorDisplay(y_true=y, y_pred=y_hat)\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this plot, there is some slight indications that we have a bit of pattern to these data.  \n",
    "What I see if I look carefully is a slight downward pattern then an upward pattern.  It makes me \n",
    "want to consider adding a quadratic term to this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins['flipper_length_sq']= penguins['flipper_length_mm']*penguins['flipper_length_mm']\n",
    "X = penguins[['flipper_length_mm', 'flipper_length_sq']]  \n",
    "y = penguins['body_mass_g']  \n",
    "\n",
    "\n",
    "# Create a linear regression model\n",
    "p_model = LinearRegression()\n",
    "\n",
    "# Fit the model on the  data\n",
    "p_model.fit(X, y)\n",
    "\n",
    "# Make predictions on the  data\n",
    "y_hat = p_model.predict(X)\n",
    "\n",
    "# Evaluate the model performance\n",
    "rmse = root_mean_squared_error(y, y_hat)\n",
    "print('Root Mean Squared Error:', rmse)\n",
    "\n",
    "# Get the coefficients and intercept\n",
    "print('Coefficients:', p_model.coef_)\n",
    "print('Intercept:', p_model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = sm.add_constant(X)\n",
    "\n",
    "#fit linear regression model\n",
    "model2 = sm.OLS(y, x2).fit()\n",
    "\n",
    "#view model summary\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below makes a residual vs predicted values plot\n",
    "display = PredictionErrorDisplay(y_true=y, y_pred=y_hat)\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that is a better residual plot.  The RMSE has dropped slightly and the $r^2$ is just slightly higher.\n",
    "Further looking at the model output we see that the quadratic term is discernibly different from zero.\n",
    "This suggests that the quadratic model is better.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, using a quadratic model is useful 1) when there is a clear quadratic pattern to the relationship\n",
    "between the target/response and the feature/predictor or 2) when there is \n",
    "a quadratic pattern in the residuals vs fitted plot after fitting a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Multicollinearity\n",
    "\n",
    "Multicollinearity is something that happens when there is substantial correlatino between the  \n",
    "\n",
    "We will use some old cigareete \n",
    "\n",
    "[<http://jse.amstat.org/v2n1/datasets.mcintyre.html>]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cigs = pd.read_csv(\"https://webpages.charlotte.edu/mschuck1/classes/DTSC2301/Data/cigarettes.csv\", na_values=['NA'])\n",
    "cigs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal in this analysis is to predict carbon monoxide from the other predictors.  We will start by building three\n",
    "separate linear regressions with Tar, Nicotine and Weight as the predictors in each.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=cigs[['Tar']]\n",
    "y=cigs['CO']\n",
    "x2 = sm.add_constant(X)\n",
    "\n",
    "#fit linear regression model\n",
    "model2 = sm.OLS(y, x2).fit()\n",
    "\n",
    "#view model summary\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=cigs[['Nicotine']]\n",
    "y=cigs['CO']\n",
    "x2 = sm.add_constant(X)\n",
    "\n",
    "#fit linear regression model\n",
    "model2 = sm.OLS(y, x2).fit()\n",
    "\n",
    "#view model summary\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=cigs[['Weight']]\n",
    "y=cigs['CO']\n",
    "x2 = sm.add_constant(X)\n",
    "\n",
    "#fit linear regression model\n",
    "model2 = sm.OLS(y, x2).fit()\n",
    "\n",
    "#view model summary\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So all of the predictors are significant on their own.  Tar and Nicotine are particularly strong predictors of CO.\n",
    "\n",
    "Next we will put them all into a model and look at the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=cigs[['Tar', 'Nicotine','Weight']]\n",
    "y=cigs['CO']\n",
    "x2 = sm.add_constant(X)\n",
    "\n",
    "#fit linear regression model\n",
    "model2 = sm.OLS(y, x2).fit()\n",
    "\n",
    "#view model summary\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple things to note here:\n",
    "1.  r^2 is not higher appreciably higher than it was for the model with Tar along\n",
    "2.  In each of the individual models, all of the predictors were significant.\n",
    "3.  For the full model, only Tar is significant.  \n",
    "\n",
    "Below is the code to tell about all the correlations among our predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a correlation matrix with predictors for \n",
    "r = X.corr()\n",
    "print (r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of code is for calculating VIF, variance inflation factor.  VIF is a way of detecting if multicollinearity is a problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = x2.columns\n",
    "\n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(x2.values, i)\n",
    "                          for i in range(len(x2.columns))]\n",
    "\n",
    "print(vif_data[1:len(x2.columns)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above suggests that there is significant multicollinearity and we should be worried about Tar and Nicotine since their VIF values are $\\gt$ 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "1. Repeat the above analysis for multicollinearity with Fit a multiple regression model for predicting penguin body mass using flipper length, bill length and bill depth.  Determine if multicollinearity is a problem with this model.  (For now ignore the quadratic term for flipper length)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
