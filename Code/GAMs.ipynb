{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generalized Additive Models\n",
        "\n",
        "Note that you should open this and run it in Google Colab [<https://colab.research.google.com>]  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZnmsRkldjM-w"
      },
      "outputs": [],
      "source": [
        " !pip install pygam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "By7WBEajjhZc"
      },
      "outputs": [],
      "source": [
        "!pip install ISLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7NSTw9Mi68v"
      },
      "outputs": [],
      "source": [
        "# import modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# plotting modules\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import subplots\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import PredictionErrorDisplay\n",
        "from sklearn.metrics import root_mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "from pygam import (s as s_gam,\n",
        "                   l as l_gam,\n",
        "                   f as f_gam,\n",
        "                   LinearGAM)\n",
        "\n",
        "from ISLP.transforms import (BSpline,\n",
        "                             NaturalSpline)\n",
        "from ISLP.models import bs, ns\n",
        "from ISLP.pygam import (approx_lam,\n",
        "                        degrees_of_freedom,\n",
        "                        plot as plot_gam,\n",
        "                        anova as anova_gam)\n",
        "\n",
        "from ISLP import load_data\n",
        "from ISLP.models import (summarize,\n",
        "                         poly,\n",
        "                         ModelSpec as MS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE8h_LleTdRw"
      },
      "source": [
        "A smoothing spline is a special case of a GAM with squared-error loss and a single feature. To fit GAMs in Python we will use the _pygam_ package which can be installed via pip install pygam. The estimator LinearGAM() uses squared-error loss, RMSE. The GAM is specified by associating each column of a model matrix with a particular smoothing operation: s for smoothing spline; l for linear, and f for factor or categorical variables. The argument 0 passed to s below indicates that this smoother will apply to the first column of a feature matrix. Below, we pass it a matrix with a single column: X_age. The argument _lam_ is penalty value for smoothing the splines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9kDcdu6TtDu"
      },
      "source": [
        "We'll again work with the Wage data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdTR0NIbSYIC"
      },
      "outputs": [],
      "source": [
        "Wage = load_data('Wage')\n",
        "y = Wage['wage']\n",
        "age = Wage['age']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dqIsL0RTQdS"
      },
      "source": [
        "The `pygam` library generally expects a matrix of features so we reshape `age` to be a matrix (a two-dimensional array) instead\n",
        "of a vector (i.e. a one-dimensional array). The `-1` in the call to the `reshape()` method tells `numpy` to impute the\n",
        "size of that dimension based on the remaining entries of the shape tuple.\n",
        "\n",
        "Let’s investigate how the fit changes with the smoothing parameter `lam`.\n",
        "The function `np.logspace()` is similar to `np.linspace()` but spaces points\n",
        "evenly on the log-scale. Below we vary `lam` from $10^{-2}$ to $10^6$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vTaJvSmnhsb"
      },
      "outputs": [],
      "source": [
        "X_age = np.asarray(age).reshape((-1,1))\n",
        "gam = LinearGAM(s_gam(0, lam=0.6))\n",
        "gam.fit(X_age, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX563PXNTOgW"
      },
      "source": [
        "We now create a grid of values for age at which we want predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peWObeiASikZ"
      },
      "outputs": [],
      "source": [
        "# create a grid of points and put them in a DataFrame\n",
        "age_grid = np.linspace(age.min(),\n",
        "                       age.max(),\n",
        "                       100)\n",
        "age_df = pd.DataFrame({'age': age_grid})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GncViDMZaYB"
      },
      "source": [
        "We can fix the degrees of freedom of the smoothing\n",
        "spline using a function included in the `ISLP.pygam` package. Below we\n",
        "find a value of 'lam'=$\\lambda$ that gives us roughly four degrees of\n",
        "freedom. We note here that these degrees of freedom include the\n",
        "unpenalized intercept and linear term of the smoothing spline, hence there are at least two\n",
        "degrees of freedom."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yj16dCt7nvT8"
      },
      "outputs": [],
      "source": [
        "# get the first term from 'gam'\n",
        "age_term = gam.terms[0]\n",
        "# get the approximately 'best' value for 'lam' based upon having the smallest squared error.\n",
        "lam_4 = approx_lam(X_age, age_term, 4)\n",
        "print(lam_4)\n",
        "age_term.lam = lam_4\n",
        "# print the approximate degrees of freedom corresponding to the value of 'lam' being 1446.7.\n",
        "degrees_of_freedom(X_age, age_term)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St4aByTMZLvQ"
      },
      "source": [
        "Let’s vary the degrees of freedom in a similar plot to above. We choose the degrees of freedom\n",
        "as the desired degrees of freedom plus one to account for the fact that these smoothing\n",
        "splines always have an intercept term. Hence, a value of one for `df` is just a linear fit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Yct_CNrHnCeX"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig, ax = subplots(figsize=(8,8))\n",
        "ax.scatter(X_age,\n",
        "           y,\n",
        "           facecolor='gray',\n",
        "           alpha=0.3)\n",
        "for df in [1,3,4,8,15]:\n",
        "    lam = approx_lam(X_age, age_term, df+1)\n",
        "    age_term.lam = lam\n",
        "    gam.fit(X_age, y)\n",
        "    ax.plot(age_grid,\n",
        "            gam.predict(age_grid),\n",
        "            label='{:d}'.format(df),\n",
        "            linewidth=4)\n",
        "ax.set_xlabel('Age', fontsize=20)\n",
        "ax.set_ylabel('Wage', fontsize=20);\n",
        "ax.legend(title='Degrees of freedom');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTDxAtm_Z93u"
      },
      "source": [
        "### Additive Models with Several Terms\n",
        "The strength of generalized additive models lies in their ability to fit multivariate regression models with more flexibility than linear models. We demonstrate two approaches: the first in a more manual fashion using natural splines and piecewise constant functions, and the second  using the `pygam` package and smoothing splines.\n",
        "\n",
        "We now fit a GAM by hand to predict\n",
        "`wage` using natural spline functions of `year` and `age`,\n",
        "treating `education` as a qualitative predictor.\n",
        "Since this is just a big linear regression model\n",
        "using an appropriate choice of basis functions, we can simply do this\n",
        "using the `sm.OLS()`  function.\n",
        "\n",
        "We will build the model matrix in a more manual fashion here, since we wish\n",
        "to access the pieces separately when constructing partial dependence plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "dTb4Varsn12j"
      },
      "outputs": [],
      "source": [
        "# make natural spline with 4 df for predictor 'age'\n",
        "ns_age = NaturalSpline(df=4).fit(age)\n",
        "# make natural spline with 5 df for predictor 'year'\n",
        "ns_year = NaturalSpline(df=5).fit(Wage['year'])\n",
        "# combine and transform age and year as well as combine\n",
        "# indicators for education level\n",
        "Xs = [ns_age.transform(age),\n",
        "      ns_year.transform(Wage['year']),\n",
        "      pd.get_dummies(Wage['education']).values]\n",
        "# horizontally stack the values from Xs into a matrix for regression\n",
        "X_bh = np.hstack(Xs)\n",
        "# fit the regression using the natural spline columns as predictors\n",
        "# note that this is building a GAM by hand rather than\n",
        "gam_bh = sm.OLS(y, X_bh).fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaRsUnZcaIRR"
      },
      "source": [
        "Here the function `NaturalSpline()` is the workhorse supporting\n",
        "the `ns()` helper function.  We chose to use all columns of the\n",
        "indicator matrix for the categorical variable `education`, making an intercept redundant.\n",
        "Finally, we stacked the three component matrices horizontally to form the model matrix `X_bh`.\n",
        "\n",
        "Natural splines are similar to basis splines that we used previously but they fit a linear equation a little bit beyond the values in the range of\n",
        "the feature whose effect we are estimating.  \n",
        "\n",
        "Partial dependence plots are a way of looking at the relationship between\n",
        "a feature and a target while holding the other predictors fixed at\n",
        "their mean value.  \n",
        "\n",
        "We now show how to construct partial dependence plots for each of the terms in our rudimentary GAM. We can do this by hand,\n",
        "given grids for `age` and `year`.\n",
        " We simply predict with new $X$ matrices, fixing all but one of the features at a time.\n",
        "\n",
        " The centering here is simply to have an understanding of the effect (differences from zero) of each predictor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Z5lHWrR-n5Td"
      },
      "outputs": [],
      "source": [
        "# create a grid of age values\n",
        "# recall that the age_grid recreated above\n",
        "age_grid = np.linspace(age.min(),\n",
        "                       age.max(),\n",
        "                       100)\n",
        "# we are making a copy of the first 100 elements of X_bh\n",
        "X_age_bh = X_bh.copy()[:100]\n",
        "X_age_bh[:] = X_bh[:].mean(0)[None,:]\n",
        "X_age_bh[:,:4] = ns_age.transform(age_grid)\n",
        "\n",
        "# get the predicted values for\n",
        "preds = gam_bh.get_prediction(X_age_bh)\n",
        "# get confidence intervals for the predictions\n",
        "bounds_age = preds.conf_int(alpha=0.05)\n",
        "# get predicted values for each age\n",
        "partial_age = preds.predicted_mean\n",
        "# get mean of the predicted values\n",
        "center = partial_age.mean()\n",
        "# center partial_age and the confidence limits\n",
        "partial_age -= center\n",
        "bounds_age -= center\n",
        "#\n",
        "fig, ax = subplots(figsize=(8,8))\n",
        "ax.plot(age_grid, partial_age, 'b', linewidth=3)\n",
        "ax.plot(age_grid, bounds_age[:,0], 'r--', linewidth=3)\n",
        "ax.plot(age_grid, bounds_age[:,1], 'r--', linewidth=3)\n",
        "ax.set_xlabel('Age')\n",
        "ax.set_ylabel('Effect on wage')\n",
        "ax.set_title('Partial dependence of age on wage', fontsize=20);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbAC3ZayeqYw"
      },
      "source": [
        "Let's explain in some detail what we did above. The idea is to create a new prediction matrix, where all but the columns belonging to `age` are constant (and set to  their training-data means). The four columns for `age` are filled in with the natural spline basis evaluated at the 100 values in `age_grid`.\n",
        "\n",
        "* We made a grid of length 100 in `age`, and created a matrix `X_age_bh` with 100 rows and the same number of columns as `X_bh`.\n",
        "* We replaced every row of this matrix with the column means of the original.\n",
        "* We then replace just the first four columns representing `age` with the natural spline basis computed at the values in `age_grid`.\n",
        "\n",
        "The remaining steps should by now be familiar.\n",
        "\n",
        "We also look at the effect of `year` on `wage`; the process is the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuiUGvTberwV"
      },
      "outputs": [],
      "source": [
        "year_grid = np.linspace(2003, 2009, 100)\n",
        "year_grid = np.linspace(Wage['year'].min(),\n",
        "                        Wage['year'].max(),\n",
        "                        100)\n",
        "X_year_bh = X_bh.copy()[:100]\n",
        "X_year_bh[:] = X_bh[:].mean(0)[None,:]\n",
        "X_year_bh[:,4:9] = ns_year.transform(year_grid)\n",
        "preds = gam_bh.get_prediction(X_year_bh)\n",
        "bounds_year = preds.conf_int(alpha=0.05)\n",
        "partial_year = preds.predicted_mean\n",
        "center = partial_year.mean()\n",
        "partial_year -= center\n",
        "bounds_year -= center\n",
        "fig, ax = subplots(figsize=(8,8))\n",
        "ax.plot(year_grid, partial_year, 'b', linewidth=3)\n",
        "ax.plot(year_grid, bounds_year[:,0], 'r--', linewidth=3)\n",
        "ax.plot(year_grid, bounds_year[:,1], 'r--', linewidth=3)\n",
        "ax.set_xlabel('Year')\n",
        "ax.set_ylabel('Effect on wage')\n",
        "ax.set_title('Partial dependence of year on wage', fontsize=20);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZ1FAxPZew9L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKWg0c0qe1su"
      },
      "source": [
        "We now fit the model using smoothing splines.  All of the\n",
        "terms are fit simultaneously, taking each other\n",
        "into account to explain the response. The `pygam` package only works with matrices, so we must convert\n",
        "the categorical series `education` to its array representation, which can be found\n",
        "with the `cat.codes` attribute of `education`. As `year` only has 7 unique values, we\n",
        "use only seven basis functions for it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8FfOvK_e4io"
      },
      "outputs": [],
      "source": [
        "gam_full = LinearGAM(s_gam(0) +\n",
        "                     s_gam(1, n_splines=7) +\n",
        "                     f_gam(2, lam=0))\n",
        "Xgam = np.column_stack([age,\n",
        "                        Wage['year'],\n",
        "                        Wage['education'].cat.codes])\n",
        "gam_full = gam_full.fit(Xgam, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evOQ0Ifce8tr"
      },
      "source": [
        "The two `s_gam()` terms result in smoothing spline fits, and use a default value for $\\lambda$  (`lam=0.6`), which is somewhat arbitrary. For the categorical term `education`, specified using a `f_gam()` term,  we specify `lam=0` to avoid any shrinkage/smoothing.\n",
        "We produce the partial dependence plot in `age` to see the effect of these choices.\n",
        "\n",
        "The values for the plot\n",
        "are generated by the `pygam` package. We provide a `plot_gam()`\n",
        "function for partial-dependence plots in `ISLP.pygam`, which makes this job easier than in our last example with natural splines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVK2G-d_fFsh"
      },
      "outputs": [],
      "source": [
        "fig, ax = subplots(figsize=(8,8))\n",
        "plot_gam(gam_full, 0, ax=ax)\n",
        "ax.set_xlabel('Age')\n",
        "ax.set_ylabel('Effect on wage')\n",
        "ax.set_title('Partial dependence of age on wage - default lam=0.6', fontsize=20);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf6_gIWefqeI"
      },
      "source": [
        "We see that the function is somewhat wiggly. It is more natural to specify the `df` than a value for `lam`.\n",
        "We refit a GAM using four degrees of freedom each for\n",
        "`age` and  `year`. Recall that the addition of one below takes into account the intercept\n",
        "of the smoothing spline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccqjzFUSfLwd"
      },
      "outputs": [],
      "source": [
        "# find best 'lam' values for smoothness\n",
        "age_term = gam_full.terms[0]\n",
        "age_term.lam = approx_lam(Xgam, age_term, df=4+1)\n",
        "year_term = gam_full.terms[1]\n",
        "year_term.lam = approx_lam(Xgam, year_term, df=4+1)\n",
        "gam_full = gam_full.fit(Xgam, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQFjSmIDfOt0"
      },
      "source": [
        "Note that updating `age_term.lam` above updates it in `gam_full.terms[0]` as well! Likewise for `year_term.lam`.\n",
        "\n",
        "Repeating the plot for `age`, we see that it is much smoother.\n",
        "We also produce the plot for `year`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDYf9UYPgFrB"
      },
      "outputs": [],
      "source": [
        "fig, ax = subplots(figsize=(8,8))\n",
        "plot_gam(gam_full, 0, ax=ax)\n",
        "ax.set_xlabel('Age')\n",
        "ax.set_ylabel('Effect on wage')\n",
        "ax.set_title('Partial dependence of age on wage', fontsize=20);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVDOLNFofRPF"
      },
      "outputs": [],
      "source": [
        "fig, ax = subplots(figsize=(8,8))\n",
        "plot_gam(gam_full,\n",
        "         1,\n",
        "         ax=ax)\n",
        "ax.set_xlabel('Year')\n",
        "ax.set_ylabel('Effect on wage')\n",
        "ax.set_title('Partial dependence of year on wage', fontsize=20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcl4HXZ0fUkI"
      },
      "source": [
        "Finally we plot `education`, which is categorical. The partial dependence plot is different, and more suitable for the set of fitted constants for each level of this variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X45-R8aRfXAG"
      },
      "outputs": [],
      "source": [
        "fig, ax = subplots(figsize=(8, 8))\n",
        "ax = plot_gam(gam_full, 2)\n",
        "ax.set_xlabel('Education')\n",
        "ax.set_ylabel('Effect on wage')\n",
        "ax.set_title('Partial dependence of wage on education',\n",
        "             fontsize=20);\n",
        "ax.set_xticklabels(Wage['education'].cat.categories, fontsize=8);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PDVlRJigslQ"
      },
      "source": [
        "The code below gives us a summary for the GAM model similar to what we had\n",
        "for our regression models.  We get p-values for our\n",
        "predictors, 'P > x' and that is for a test of whether or not the\n",
        "predictor improves the performance of the model.  There is also\n",
        "an AIC value and something like an 'R-squared' value called 'Pseudo R-squared'.  \n",
        "\n",
        "With the exception of AIC, the output here is estimated and should be\n",
        "taken as 'estimates' rather than as hard values.  For example, if\n",
        "you got a p-value of 0.042 from this output and you were using\n",
        "a significance level of 0.05 you should be quite careful about\n",
        "saying the former was clearly less than the latter.\n",
        "\n",
        "Of course, you probably should be very careful using significance\n",
        "levels anyway.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0pwI3iugofJ"
      },
      "outputs": [],
      "source": [
        "gam_full.summary()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
