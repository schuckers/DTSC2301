{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multple Linear Regression\n",
    "\n",
    "The world is more complicated than two dimensions and so we need models for multiple dimensions and multiple features/predictors. \n",
    "\n",
    "Below we will look at models that are of the form:\n",
    " $$ Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_3 + \\ldots + \\beta_p X_p + \\epsilon$$\n",
    "\n",
    " We now have multiple predictors, $p$ of them in fact.  And so we have some changes to make and so things that will remain the same.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the libraries and functions that we will need as we do this work.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    " \n",
    "import scipy.stats as st\n",
    "import statsmodels.api as sm \n",
    "import pylab as py \n",
    "\n",
    "# here are some of the tools we will use for our analyses\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import PredictionErrorDisplay\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ames Housing Data\n",
    "We'll start with the Ames Housing Data again.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data to dataframe called ames\n",
    "ames = pd.read_csv(\"https://webpages.charlotte.edu/mschuck1/classes/DTSC2301/Data/Ames_house_prices.csv\", na_values=['?'])\n",
    "# replace the ? in the data with NaN for missing values\n",
    "ames.replace([' ?'],np.nan)\n",
    "# show information about the dataframe\n",
    "ames.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# below we build a multiple regression model with three predictors\n",
    "# Those predictors are LotArea, GrLivArea and BsmtFinSF1 and we put these all into X \n",
    "# \n",
    "# Our target variable will be the SalePrice \n",
    "\n",
    "X = ames[['LotArea', 'GrLivArea', 'BsmtFinSF1']]  \n",
    "y = ames['SalePrice']  \n",
    "\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model on the  data\n",
    "model.fit(X, y)\n",
    "\n",
    "# Make predictions on the  data\n",
    "y_hat = model.predict(X)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = root_mean_squared_error(y, y_hat)\n",
    "print('Root Mean Squared Error:', rmse)\n",
    "\n",
    "# Get the coefficients and intercept\n",
    "# note the coefficients will be in the same order as the  data frame\n",
    "print('Coefficients:', model.coef_)\n",
    "print('Intercept:', model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the RMSE is still the average difference between the predicted and observed response values.  Here that means that for this model the average difference between a predicted\n",
    "sale price and the actual sale price for a home in Ames, Iowa is \\$ 52475.\n",
    "\n",
    "Our coefficients now have a slightly different interpretation.  Starting with the coefficient for *LotArea*, we can say that for each additional square foot \n",
    "of lot that a property in Ames, Iowa has then we predict that the sales price for that house will increase by \\$0.33 assuming that the other predictors \n",
    "remain constant.  That last phrase, _that the other predictors remain constant_, is important.\n",
    "\n",
    "Moving to the coefficient for *GrLivArea*, for every additional square foot of liveable space in the house we expect that the sales price of a house in Ames, IA will increase by \\$97.8 assuming\n",
    "that *Lot Area* and *BsmtFinSF1* are fixed.  \n",
    "\n",
    "Lastly, for each additional square foot of finished basement, we predict that that sales price of a house in Ames will increase by \\$42.3 if the lot area and the general living area are \n",
    "held constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for this particular model sm.OLS formulation we need to add a \n",
    "# column of 1's to the feature array\n",
    "#add constant to predictor variables\n",
    "# Note that OLS stands for Ordinary Least Squares which is the \n",
    "# methodology used to get our estimates\n",
    "x2 = sm.add_constant(X)\n",
    "\n",
    "#fit linear regression model\n",
    "model2 = sm.OLS(y, x2).fit()\n",
    "\n",
    "#view model summary\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# below makes a residual vs predicted values plot\n",
    "display = PredictionErrorDisplay(y_true=y, y_pred=y_hat)\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ooof, that does not look good. There is increasing variation in the residuals as the predicted values increase, heteroscedasticity, so our linear model is not appropriate here.  \n",
    "\n",
    "Let's find some other data to look at.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blue Jay Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the blue jay data\n",
    "bluejay = pd.read_csv(\"https://webpages.charlotte.edu/mschuck1/classes/DTSC2301/Data/BlueJays.csv\", na_values=['NA'])\n",
    "# remove rows with missing data\n",
    "bluejay.dropna(inplace=True)\n",
    "bluejay.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with a model with just *Head* as a predictor.  Here's what we had before in _IntroLinearRegression.ipynb_.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In sklearn we first need to create a model object \n",
    "# and here it is a linear regression\n",
    "bluejay_model1= LinearRegression()\n",
    "# note below that the x needs to be a two dimensional array so we \n",
    "# need the double brackets here\n",
    "bluejay_x=bluejay[['Skull']]\n",
    "# y needs to be a one dimensional array so single brackets work\n",
    "bluejay_y=bluejay['Mass']\n",
    "bluejay_model1.fit(bluejay_x, bluejay_y)\n",
    "\n",
    "# make the residual vs fitted plot\n",
    "bluejay_y_hat = bluejay_model1.predict(bluejay_x)\n",
    "# below makes a \n",
    "display = PredictionErrorDisplay(y_true=bluejay_y, y_pred=bluejay_y_hat)\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is code for making the qqplot\n",
    "\n",
    "# get the predicted values from the model\n",
    "bluejay_y_hat = bluejay_model1.predict(bluejay_x)  \n",
    "# calculate the residuals \n",
    "bluejay_residuals = bluejay_y -bluejay_y_hat\n",
    "# generate the qq plot and put a line through the points to help us visualize the relationship here    \n",
    "sm.qqplot(bluejay_residuals, line ='s') \n",
    "# \n",
    "py.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of these plots look good.  Let's get the model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this particular model formulation we need to add a \n",
    "# column of 1's to the feature array\n",
    "#add constant to predictor variables\n",
    "bluejay_x2 = sm.add_constant(bluejay_x)\n",
    "\n",
    "#fit linear regression model\n",
    "bluejay_model2 = sm.OLS(bluejay_y, bluejay_x2).fit()\n",
    "\n",
    "#view model summary\n",
    "print(bluejay_model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model via the RMSE\n",
    "rmse = root_mean_squared_error(bluejay_y, bluejay_y_hat)\n",
    "print('Root Mean Squared Error:', rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Regression\n",
    "Now we are going to add some predictors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# below we build a multiple regression model with three predictors\n",
    "#  Predictors here are Head, BillDepth, and BillLength\n",
    "# Our target variable will be the Mass of the blue jay \n",
    "\n",
    "X = bluejay[['Head', 'BillDepth', 'BillLength']]  \n",
    "y = bluejay['Mass']  \n",
    "\n",
    "\n",
    "# Create a linear regression model\n",
    "blue_model = LinearRegression()\n",
    "\n",
    "# Fit the model on the  data\n",
    "blue_model.fit(X, y)\n",
    "\n",
    "# Make predictions on the  data\n",
    "y_hat = blue_model.predict(X)\n",
    "\n",
    "# Evaluate the model performance\n",
    "rmse = root_mean_squared_error(y, y_hat)\n",
    "print('Root Mean Squared Error:', rmse)\n",
    "\n",
    "# Get the coefficients and intercept\n",
    "print('Coefficients:', blue_model.coef_)\n",
    "print('Intercept:', blue_model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below makes a residual plot\n",
    "display = PredictionErrorDisplay(y_true=y, y_pred=y_hat)\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is code for making the qqplot\n",
    "\n",
    "\n",
    "# calculate the residuals \n",
    "bluejay_residuals = y - y_hat\n",
    "# generate the qq plot and put a line through the points to help us visualize the relationship here    \n",
    "sm.qqplot(bluejay_residuals, line ='s') \n",
    "# \n",
    "py.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of the plots above look good, so let's look at the model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this particular model formulation we need to add a \n",
    "# column of 1's to the feature array\n",
    "#add constant to predictor variables\n",
    "x2 = sm.add_constant(X)\n",
    "\n",
    "#fit linear regression model using OLS\n",
    "blue_model2 = sm.OLS(y, x2).fit()\n",
    "\n",
    "#view model summary\n",
    "print(blue_model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = root_mean_squared_error(y, y_hat)\n",
    "print('Root Mean Squared Error:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's take a crack at interpretting this output.\n",
    "\n",
    "For $r^2$ we have the $46.3\\%$ of the variability in blue jay mass can be explained by the relationship with head size, bill depth and bill length.  Contrast this with $30.6\\%$ that we had for $r^2$ with the model that just had 'head' as a predictor.  So we are gaining something by adding the BillDepth and BillLength.\n",
    "\n",
    "Our RMSE here is $3.480$ g which means that the average magnitude of the difference between the predicted blue jay mass and the observed blue jay mass is $3.48$ grams.  This is better than our model with just 'head' which had an RMSE of $3.96$.  \n",
    "\n",
    "Turning to the model coefficients:\n",
    "\n",
    "Our y-intercept is estimated to be $-50.2$ which means that for a blue jay with a Bill depth of 0 mm, a bill length of 0 mm and a head size of 0mm, we would predict that their body mass would be -50.2 g.\n",
    "\n",
    "For the coefficient of head which has a value of $2.45$, we predict that for each additional mm of head size that a blue jays mass will increase by $2.45$ grams assuming that bill depth and bill length of that blue jay remain the same.\n",
    "\n",
    "Moving to *BillDepth*, assuming that head size and bill length of a blue jay are unchanged, for each additional mm of bill depth that a blue jay has, we predict that the mass of that blue jay will be increased by $2.81$ g.\n",
    "\n",
    "Lastly for each additional mm of bill length that a blue jay has, this model predicts that that blue jay's mass will decrease by $1.51$ g if the head size and bill depth are held constant. \n",
    "\n",
    "Some other notes on this output.  First all of the p-values for testing if the coefficients are zero are small so we can conclude that each of the coefficients in the model is significantly/discernibly different from zero.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F-test of model utility\n",
    " \n",
    "Here is another way to evaluate the overall utility of a model.  The hypothesis being carried out here is the following:\n",
    "\n",
    "$H_0: \\beta_1 = \\beta_2 = \\beta_3 = \\ldots = \\beta_p=0$ vs. $H_a: $not $H_0$.\n",
    "\n",
    "The results for this test can be found in the output above:\n",
    "\n",
    "F-statistic:                     34.16\n",
    "\n",
    "Prob (F-statistic):           5.35e-16\n",
    "\n",
    "The p-value is represented by *Prob (F-statistic)* which here is very small, $5.35 x 10^{-16}$ and so we can reject the null hypothesis and conclude that at least one of our coefficients, our $\\beta$'s, is not zero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $R^2$ squared adjusted\n",
    "\n",
    "For the model above the $r^2_{adj}$ is 0.449.  By itself this is just our $r^2$ value with a small amount subtracted for having three predictors in the model.  The measure, $r^2_{adj}$ is primarily used for comparing across models, specifically when they are of different sizes, ie have different $p$'s or the number of predictors.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blue Jay models with Interaction\n",
    "\n",
    "So let's take a look at another model for predicting blue jay mass, this time we will add the variable *Sex* to the model with *BillLength* as the other predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below we build a multiple regression model with three predictors\n",
    "# Those predictors are LotArea, GrLivArea and BsmtFinSF1\n",
    "# \n",
    "# Our target variable will be the SalePrice \n",
    "\n",
    "X = bluejay[['BillLength', 'Sex']]  \n",
    "y = bluejay['Mass']  \n",
    "\n",
    "\n",
    "# Create a linear regression model\n",
    "blue_model2 = LinearRegression()\n",
    "\n",
    "# Fit the model on the  data\n",
    "blue_model2.fit(X, y)\n",
    "\n",
    "# Make predictions on the  data\n",
    "y_hat = blue_model2.predict(X)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = root_mean_squared_error(y, y_hat)\n",
    "print('Root Mean Squared Error:', rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this particular model formulation we need to add a \n",
    "# column of 1's to the feature array\n",
    "#add constant to predictor variables\n",
    "x2 = sm.add_constant(X)\n",
    "\n",
    "#fit linear regression model\n",
    "blue_model2 = sm.OLS(y, x2).fit()\n",
    "\n",
    "#view model summary\n",
    "print(blue_model2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have a model now that is really two models: one for females (*Sex ==0*) and one for males (*Sex ==1*).  \n",
    "\n",
    "Let's look at the interpretation of the coefficients.  Some of these interpretation are different due to the use of the indicator variable *Sex* here.\n",
    "\n",
    "$40.0$ here is the predicted mass of a female blue jay with a bill length of $0$ mm.  Note that when the variable *Sex* takes the value *0* that represents a female blue jay.\n",
    "\n",
    "For each additional mm of bill length for a blue jay, the predicted increase of mass of that blue jay is $1.23$ g assuming that the *Sex* of the blue jay does not change.\n",
    "\n",
    "The coefficient for the variable *Sex* represents that the predicted difference in mass between a male blue jay and a female blue jays when the blue jay has a bill length of zero mm is $1.84$.\n",
    "\n",
    "Next we will look at a model with an **interaction** term between *BillLength* and *Sex*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Our target variable will be the SalePrice \n",
    "bluejay['BillDepth_Sex'] = bluejay['BillDepth']*bluejay['Sex']\n",
    "\n",
    "X = bluejay[['BillDepth', 'Sex', 'BillDepth_Sex']]  \n",
    "y = bluejay['Mass']  \n",
    "\n",
    "\n",
    "# Create a linear regression model\n",
    "bluejay_model3 = LinearRegression()\n",
    "\n",
    "# Fit the model on the  data\n",
    "bluejay_model3.fit(X, y)\n",
    "\n",
    "# Make predictions on the  data\n",
    "y_hat = bluejay_model3.predict(X)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = root_mean_squared_error(y, y_hat)\n",
    "print('Root Mean Squared Error:', rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this particular model formulation we need to add a \n",
    "# column of 1's to the feature array\n",
    "#add constant to predictor variables\n",
    "x2 = sm.add_constant(X)\n",
    "\n",
    "#fit linear regression model\n",
    "blue_model3 = sm.OLS(y, x2).fit()\n",
    "\n",
    "#view model summary\n",
    "print(blue_model3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So some things to look in this output.  The coefficients for the variables *Sex* and the interaction term *BillDepth_Sex* are not \n",
    "discernibly different from zero.  So we might consider dropping them from the model, though when we fit the model without *BillDepth_Sex* the coefficient for *Sex* is significant if barely.\n",
    "\n",
    "To add to the discussion, the smaller model above has a noticeably smaller $r^2$ and $r^2_{adj}$ so that the\n",
    "fuller model with the interaction term is generally performing better --- lower RMSE too --- than \n",
    "the model without the interaction. \n",
    "\n",
    "This is where modelling becomes harder.  As we have more and more features to consider, finding the right combination of\n",
    "features to make a good model is important.  More to come.\n",
    "\n",
    "Let's look at the coefficients next.\n",
    "\n",
    "For a female blue jay with a bill depth of 0 mm, we would predict their body mass to be 20.5.\n",
    "\n",
    "For a female blue jay for each additional mm of bill depth, we expect that their body mass would increase by 6.15 g.\n",
    "\n",
    "For a male blue jay with a bill depth of 0mm, we predict that their body mass would be 31.6 g higher than a female blue jays.\n",
    "\n",
    "For a male blue jay the amount of body mass that we predict a blue jay to gain for each additional mm of bill depth is 3.65 g less\n",
    "than what we would expect the gain to be for a female blue jay.\n",
    "\n",
    "Because of the structure of the indicator variables that we have created, the interpretations for the last two coefficients (for *Sex* and for *BillDepth_Sex*) are as differences.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "1. Using the Blue Jays data, fit a regression model to predict body mass using *Sex* and *Skull*.  Make the residual plot and the QQplot.  Determine if the linear model is appropriate for these data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using the regression that you created in Task 1, find and interpret the $r^2$ and the $RMSE$ values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using the regression that you created in Task 1, find and interpret all of the coefficients for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Predict the body mass of a male blue jay with a Skull size of 31 mm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Predict the body mass of a female blue jay with a Skull size of 31 mm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What is the difference in your predictions from Task 4 and Task 5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Create a new variable that is an interaction between *Sex* and *Skull*.  Create a model with this new variable added to the terms in the model from Task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Interpret the coefficients for the model you make in Task 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Based upon $r^2_{adj}$ which model is best from among those in this notebook for predicting blue jay mass. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Based upon RMSE which model is best from among those in the notebook for predicting blue jay mass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.  For the model in you fit in Task 4, which of the predictors were statistically discernible from zero?  How do you know?  What does this tell you about the value of those predictors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12.  What are the p-value and your conclusions from an F-test of model utility for the model you fit in Task 4?  How does that connect with your answers in Task 7."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
